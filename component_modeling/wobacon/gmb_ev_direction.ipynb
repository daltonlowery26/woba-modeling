{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66563c33",
   "metadata": {},
   "source": [
    "### lgb to model wobacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80e416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, PredefinedSplit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b48f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Projects/Coding Projects/woba modeling/data/')\n",
    "df = pd.read_csv('pitch_cleaned.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16116f",
   "metadata": {},
   "source": [
    "##### Cleaning for Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abeb93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['description'] == 'hit_into_play']\n",
    "df = df[['batter','year', 'woba_value', 'launch_speed', 'launch_angle', 'spray_angle']]\n",
    "df = df[df['launch_speed'].notna()] # mcar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d897b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd80137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['year'] < 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748ae828",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (df_train[['launch_speed', 'launch_angle', 'spray_angle']])\n",
    "y = df_train['woba_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37995345",
   "metadata": {},
   "source": [
    "##### Train Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2cc10",
   "metadata": {},
   "source": [
    "no need for a test set as I am purposely holding out 2025 data. I want to test on all 2025 data to compare the predection power of this model to xwobacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "588c9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=26) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bc7ff",
   "metadata": {},
   "source": [
    "##### Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c50c75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor(random_state=26, n_jobs=-1, metric=['mae', 'rmse'], objective='quantile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e450d758",
   "metadata": {},
   "source": [
    "##### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7800b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d0904ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Randomized Search for quantile: 0.1\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.1, max_bin=63, metric=['mae', 'rmse'], n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 183584, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "Best parameters for quantile 0.1: {'subsample': 0.6000000000000001, 'num_leaves': 94, 'n_estimators': 200, 'min_data_in_leaf': 1, 'max_depth': 12, 'learning_rate': 0.1, 'lambda_l2': 10, 'lambda_l1': 1, 'colsample_bytree': 0.7, 'boosting_type': 'gbdt'}\n",
      "Best score for quantile 0.1: -0.11847589550443538\n",
      "Running Randomized Search for quantile: 0.2\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.2, max_bin=63, metric=['mae', 'rmse'], n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 183584, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "Best parameters for quantile 0.2: {'subsample': 0.8, 'num_leaves': 94, 'n_estimators': 600, 'min_data_in_leaf': 4, 'max_depth': 10, 'learning_rate': 0.01, 'lambda_l2': 10, 'lambda_l1': 3, 'colsample_bytree': 0.9, 'boosting_type': 'gbdt'}\n",
      "Best score for quantile 0.2: 0.17458193925968357\n",
      "Running Randomized Search for quantile: 0.3\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.3, max_bin=63, metric=['mae', 'rmse'], n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 183584, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "Best parameters for quantile 0.3: {'subsample': 0.4666666666666667, 'num_leaves': 58, 'n_estimators': 300, 'min_data_in_leaf': 10, 'max_depth': 12, 'learning_rate': 0.1, 'lambda_l2': 3, 'lambda_l1': 1, 'colsample_bytree': 0.9, 'boosting_type': 'gbdt'}\n",
      "Best score for quantile 0.3: 0.29611367093943075\n",
      "Running Randomized Search for quantile: 0.4\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.4, max_bin=63, metric=['mae', 'rmse'], n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 183584, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "Best parameters for quantile 0.4: {'subsample': 0.4, 'num_leaves': 53, 'n_estimators': 700, 'min_data_in_leaf': 13, 'max_depth': 10, 'learning_rate': 0.1, 'lambda_l2': 10, 'lambda_l1': 0.01, 'colsample_bytree': 0.9, 'boosting_type': 'gbdt'}\n",
      "Best score for quantile 0.4: 0.3860713912747995\n",
      "Running Randomized Search for quantile: 0.5\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.5, max_bin=63, metric=['mae', 'rmse'], n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 183584, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "Best parameters for quantile 0.5: {'subsample': 0.8, 'num_leaves': 84, 'n_estimators': 900, 'min_data_in_leaf': 30, 'max_depth': 12, 'learning_rate': 0.01, 'lambda_l2': 3, 'lambda_l1': 5, 'colsample_bytree': 1.0, 'boosting_type': 'gbdt'}\n",
      "Best score for quantile 0.5: 0.41718962255272973\n",
      "Running Randomized Search for quantile: 0.6\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.6, max_bin=63, metric=['mae', 'rmse'], n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 183584, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "Best parameters for quantile 0.6: {'subsample': 0.8, 'num_leaves': 94, 'n_estimators': 600, 'min_data_in_leaf': 4, 'max_depth': 10, 'learning_rate': 0.01, 'lambda_l2': 10, 'lambda_l1': 3, 'colsample_bytree': 0.9, 'boosting_type': 'gbdt'}\n",
      "Best score for quantile 0.6: 0.4348694283378679\n",
      "Running Randomized Search for quantile: 0.7\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.7, max_bin=63, metric=['mae', 'rmse'], n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 183584, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Start training from score 0.900000\n",
      "Best parameters for quantile 0.7: {'subsample': 0.4666666666666667, 'num_leaves': 58, 'n_estimators': 300, 'min_data_in_leaf': 10, 'max_depth': 12, 'learning_rate': 0.1, 'lambda_l2': 3, 'lambda_l1': 1, 'colsample_bytree': 0.9, 'boosting_type': 'gbdt'}\n",
      "Best score for quantile 0.7: 0.27852425875525244\n",
      "Running Randomized Search for quantile: 0.8\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.8, max_bin=63, metric=['mae', 'rmse'], n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 183584, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Info] Start training from score 0.900000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters for quantile 0.8: {'subsample': 0.7333333333333334, 'num_leaves': 74, 'n_estimators': 1200, 'min_data_in_leaf': 23, 'max_depth': 6, 'learning_rate': 0.1, 'lambda_l2': 20, 'lambda_l1': 0.001, 'colsample_bytree': 0.9, 'boosting_type': 'gbdt'}\n",
      "Best score for quantile 0.8: 0.14305561926640742\n",
      "Running Randomized Search for quantile: 0.9\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.9, max_bin=63, metric=['mae', 'rmse'], n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 183584, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Start training from score 1.250000\n",
      "Best parameters for quantile 0.9: {'subsample': 0.6000000000000001, 'num_leaves': 94, 'n_estimators': 200, 'min_data_in_leaf': 1, 'max_depth': 12, 'learning_rate': 0.1, 'lambda_l2': 10, 'lambda_l1': 1, 'colsample_bytree': 0.7, 'boosting_type': 'gbdt'}\n",
      "Best score for quantile 0.9: -0.5242220160830271\n"
     ]
    }
   ],
   "source": [
    "rnd_search_params = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],          \n",
    "    'num_leaves': np.linspace(2, 100, 20, dtype=int),\n",
    "    'max_depth': np.linspace(2, 12, 10, dtype=int),  \n",
    "    'min_data_in_leaf': np.linspace(1, 30, 10, dtype=int),         \n",
    "    'subsample': np.linspace(0.4, 0.8, 7),               \n",
    "    'colsample_bytree': np.linspace(0.6, 1.0, 5),\n",
    "    'n_estimators': np.linspace(100, 1500, 15, dtype=int),\n",
    "    'lambda_l2': [1, 3, 5, 10, 20],\n",
    "    'lambda_l1': [0.001, 0.01, 1, 3, 5]\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\": [lgb.early_stopping(stopping_rounds=40, verbose=False)], \n",
    "    \"eval_set\": [(x_val, y_val)],\n",
    "    \"eval_metric\": \"rmse\" \n",
    "}\n",
    "\n",
    "# for early stopping\n",
    "x_combined = np.concatenate((x_train, x_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "split_index = [-1] * len(x_train) + [0] * len(x_val)\n",
    "pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "all_best_params = {}\n",
    "all_best_scores = {}\n",
    "\n",
    "model.set_params(max_bin=63)\n",
    "for q in quantiles:\n",
    "    print(f\"Running Randomized Search for quantile: {q}\")\n",
    "    \n",
    "    rnd_searcher = RandomizedSearchCV(model, param_distributions=rnd_search_params, cv=pds,\n",
    "                                    n_iter=200, random_state=26, verbose=1, n_jobs=5) \n",
    "    \n",
    "    model.set_params(alpha=q)\n",
    "    print(model.get_params)\n",
    "    search = rnd_searcher.fit(x_combined, y_combined, **fit_params)\n",
    "    \n",
    "    print(f\"Best parameters for quantile {q}: {search.best_params_}\")\n",
    "    print(f\"Best score for quantile {q}: {search.best_score_}\")\n",
    "    \n",
    "    all_best_params[q] = search.best_params_\n",
    "    all_best_scores[q] = search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac5100",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00bc454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'boosting_type': ['dart', 'gbdt'],\n",
    "        'subsample': [0.45, 0.5, 0.55], \n",
    "        'num_leaves':  [8, 9, 10], \n",
    "        'n_estimators': [350, 400, 450], \n",
    "        'min_data_in_leaf': [16, 18, 20], \n",
    "        'max_depth': [8, 9], \n",
    "        'max_bin': [63], \n",
    "        'learning_rate': [0.1, 0.15], \n",
    "        'lambda_l2': [0.5, 1], \n",
    "        'colsample_bytree': [0.75, 0.8]\n",
    "        }\n",
    "\n",
    "\n",
    "# for early stopping\n",
    "x_combined = np.concatenate((x_train, x_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "split_index = [-1] * len(x_train) + [0] * len(x_val)\n",
    "pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\": [lgb.early_stopping(stopping_rounds=40, verbose=False)], \n",
    "    \"eval_set\": [(x_val, y_val)],\n",
    "    \"eval_metric\": \"rmse\" \n",
    "}\n",
    "\n",
    "\n",
    "grid_searcher = GridSearchCV(model, param_grid=grid, cv=pds, verbose=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aaf053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 2592 candidates, totalling 2592 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 266\n",
      "[LightGBM] [Info] Number of data points in the train set: 169715, number of used features: 5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Start training from score 0.373572\n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'lambda_l2': 1, 'learning_rate': 0.15, 'max_bin': 63, 'max_depth': 8, 'min_data_in_leaf': 18, 'n_estimators': 350, 'num_leaves': 9, 'subsample': 0.45}\n",
      "0.22591349039763697\n",
      "['Column_0' 'Column_1' 'Column_2' 'Column_3' 'Column_4']\n"
     ]
    }
   ],
   "source": [
    "grid_searcher.fit(x_combined, y_combined, **fit_params)\n",
    "print(grid_searcher.best_params_)\n",
    "print(grid_searcher.best_score_)\n",
    "print(grid_searcher.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4afe9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best = {'objective':'regression', 'type': 'quantilie', 'boosting_type': 'dart', 'colsample_bytree': 0.75, 'lambda_l2': 1, 'learning_rate': 0.15, 'max_bin': 63, 'max_depth': 8, 'min_data_in_leaf': 18, 'n_estimators': 350, 'num_leaves': 9, 'subsample': 0.45}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa024a79",
   "metadata": {},
   "source": [
    "#### Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c215ee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best parameters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_numpy_types(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_numpy_types(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [convert_numpy_types(i) for i in obj]\n",
    "    return obj\n",
    "\n",
    "serializable_params = convert_numpy_types(all_best_params)\n",
    "\n",
    "with open('ev_dir_params.json', 'w') as f:\n",
    "    json.dump(serializable_params, f, indent=4)\n",
    "\n",
    "print(\"Saved best parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f8995a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 156046, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Start training from score 0.377374\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 156046, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Start training from score 0.377374\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 156046, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Start training from score 0.377374\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 156046, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Start training from score 0.377374\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 156046, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Start training from score 0.377374\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 156046, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Start training from score 0.377374\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 156046, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Info] Start training from score 0.377374\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 156046, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Info] Start training from score 0.377374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 156046, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Start training from score 0.377374\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for q in quantiles:\n",
    "    quantile_model = lgb.LGBMRegressor(**all_best_params[q], alpha=q, random_state=26, n_jobs=-1)\n",
    "    quantile_model.fit(x_train, y_train, \n",
    "                       eval_set=[(x_val, y_val)], \n",
    "                       callbacks=[lgb.early_stopping(stopping_rounds=40, verbose=False)])\n",
    "    models[q] = quantile_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f1543",
   "metadata": {},
   "source": [
    "##### Testing on 2025 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d221207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_25 = df[df['year'] == 2025]\n",
    "x_25 = df_25[['launch_speed', 'launch_angle', 'spray_angle']]\n",
    "y_25 = df_25['woba_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f355e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "RMSE: 0.38167381121129673\n"
     ]
    }
   ],
   "source": [
    "y_pred = models[.5].predict(x_25)\n",
    "rmse = np.sqrt(mean_squared_error(y_25, y_pred))\n",
    "results_df = pd.DataFrame({'actual': y_25, 'predicted': y_pred})\n",
    "results_df = results_df.join(df[['batter', 'year']])\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0e96e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp4AAAHFCAYAAABb1/k6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABadUlEQVR4nO3dd1xW9f//8efFHgLKElEE98iZ5i63OLMszZGjYZmZmntkYuZOs6ys1I98HKWV5lfNLHdDzZGWprn33uJCkPfvD39cHy8vQCU9GDzutxs3uc55n3Ne5wXCk7MumzHGCAAAAHjAXDK6AAAAAGQNBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwD/OrGxsbLZbCl+9OrV64Fsc9u2bYqJidH+/fsfyPr/if3798tmsyk2NjajS0m3RYsWKSYmJqPLAPCAuWV0AQCQXlOnTlXRokUdpoWHhz+QbW3btk1DhgxRjRo1FBUV9UC2kV65cuXSmjVrVKBAgYwuJd0WLVqkjz/+mPAJZHIETwD/WiVKlFD58uUzuox/JCEhQTabTW5u6f9x7OnpqUqVKt3Hqqxz5coV+fj4ZHQZACzCqXYAmdbs2bNVuXJl+fr6Klu2bIqOjtamTZscxmzYsEEtW7ZUVFSUvL29FRUVpVatWunAgQP2MbGxsWrevLkkqWbNmvbT+smntqOiotShQwen7deoUUM1atSwv165cqVsNpumT5+unj17Knfu3PL09NTu3bslSUuXLlXt2rXl7+8vHx8fVa1aVcuWLbvjfqZ0qj0mJkY2m01//vmnmjdvroCAAAUGBqpHjx5KTEzUjh07VL9+ffn5+SkqKkqjR492WGdyrTNmzFCPHj0UFhYmb29vVa9e3amHkjR//nxVrlxZPj4+8vPzU926dbVmzRqHMck1/f7773r22WeVI0cOFShQQB06dNDHH38sSQ6XTSRf1vDxxx/riSeeUGhoqHx9fVWyZEmNHj1aCQkJTv0uUaKE1q9fr8cff1w+Pj7Knz+/Ro4cqaSkJIex58+fV8+ePZU/f355enoqNDRUDRs21N9//20fc/36db377rsqWrSoPD09FRISohdeeEGnTp2649cEQMoIngD+tW7cuKHExESHj2TDhw9Xq1atVLx4cX311VeaPn264uLi9Pjjj2vbtm32cfv371eRIkU0fvx4/fDDDxo1apSOHTumxx57TKdPn5YkNWrUSMOHD5d0MwStWbNGa9asUaNGjdJVd//+/XXw4EF9+umnWrBggUJDQzVjxgzVq1dP/v7++u9//6uvvvpKgYGBio6OvqvwmZoWLVqodOnSmjNnjjp27Kj3339fb775pp566ik1atRI3377rWrVqqW+fftq7ty5TssPGDBAe/fu1eTJkzV58mQdPXpUNWrU0N69e+1jvvjiCzVt2lT+/v768ssvNWXKFJ07d041atTQL7/84rTOZs2aqWDBgvr666/16aefatCgQXr22Wclyd7bNWvWKFeuXJKkPXv2qHXr1po+fboWLlyol156SWPGjNGrr77qtO7jx4+rTZs2ev755zV//nw1aNBA/fv314wZM+xj4uLiVK1aNX322Wd64YUXtGDBAn366acqXLiwjh07JklKSkpS06ZNNXLkSLVu3VrfffedRo4cqSVLlqhGjRq6evVqur8mQJZmAOBfZurUqUZSih8JCQnm4MGDxs3NzbzxxhsOy8XFxZmwsDDTokWLVNedmJhoLl26ZHx9fc0HH3xgn/71118bSWbFihVOy0RGRpr27ds7Ta9evbqpXr26/fWKFSuMJPPEE084jLt8+bIJDAw0TZo0cZh+48YNU7p0aVOhQoU0umHMvn37jCQzdepU+7TBgwcbSWbs2LEOY8uUKWMkmblz59qnJSQkmJCQENOsWTOnWh999FGTlJRkn75//37j7u5uXn75ZXuN4eHhpmTJkubGjRv2cXFxcSY0NNRUqVLFqaa3337baR9ef/11cze/km7cuGESEhLMtGnTjKurqzl79qx9XvXq1Y0k89tvvzksU7x4cRMdHW1//c477xhJZsmSJalu58svvzSSzJw5cxymr1+/3kgyn3zyyR1rBeCMI54A/rWmTZum9evXO3y4ubnphx9+UGJiotq1a+dwNNTLy0vVq1fXypUr7eu4dOmS+vbtq4IFC8rNzU1ubm7Kli2bLl++rO3btz+Qup955hmH16tXr9bZs2fVvn17h3qTkpJUv359rV+/XpcvX07Xtho3buzwulixYrLZbGrQoIF9mpubmwoWLOhweUGy1q1by2az2V9HRkaqSpUqWrFihSRpx44dOnr0qNq2bSsXl//9SsmWLZueeeYZrV27VleuXElz/+9k06ZNevLJJxUUFCRXV1e5u7urXbt2unHjhnbu3OkwNiwsTBUqVHCYVqpUKYd9+/7771W4cGHVqVMn1W0uXLhQ2bNnV5MmTRy+JmXKlFFYWJjD9xCAu8fNRQD+tYoVK5bizUUnTpyQJD322GMpLndrQGrdurWWLVumQYMG6bHHHpO/v79sNpsaNmz4wE6nJp9Cvr3e5NPNKTl79qx8fX3veVuBgYEOrz08POTj4yMvLy+n6RcvXnRaPiwsLMVpf/zxhyTpzJkzkpz3Sbr5hIGkpCSdO3fO4QailMam5uDBg3r88cdVpEgRffDBB4qKipKXl5fWrVun119/3elrFBQU5LQOT09Ph3GnTp1S3rx509zuiRMndP78eXl4eKQ4P/kyDAD3huAJINMJDg6WJH3zzTeKjIxMddyFCxe0cOFCDR48WP369bNPj4+P19mzZ+96e15eXoqPj3eafvr0aXstt7r1COKt9U6YMCHVu9Nz5sx51/XcT8ePH09xWnLAS/43+drIWx09elQuLi7KkSOHw/Tb9z8t8+bN0+XLlzV37lyHr+XmzZvveh23CwkJ0eHDh9McExwcrKCgIC1evDjF+X5+funePpCVETwBZDrR0dFyc3PTnj170jyta7PZZIyRp6enw/TJkyfrxo0bDtOSx6R0FDQqKkp//vmnw7SdO3dqx44dKQbP21WtWlXZs2fXtm3b1KVLlzuOt9KXX36pHj162MPigQMHtHr1arVr106SVKRIEeXOnVtffPGFevXqZR93+fJlzZkzx36n+53c2l9vb2/79OT13fo1MsZo0qRJ6d6nBg0a6O2339by5ctVq1atFMc0btxYs2bN0o0bN1SxYsV0bwuAI4IngEwnKipK77zzjgYOHKi9e/eqfv36ypEjh06cOKF169bJ19dXQ4YMkb+/v5544gmNGTNGwcHBioqK0qpVqzRlyhRlz57dYZ0lSpSQJH3++efy8/OTl5eX8uXLp6CgILVt21bPP/+8OnfurGeeeUYHDhzQ6NGjFRISclf1ZsuWTRMmTFD79u119uxZPfvsswoNDdWpU6f0xx9/6NSpU5o4ceL9btNdOXnypJ5++ml17NhRFy5c0ODBg+Xl5aX+/ftLunnZwujRo9WmTRs1btxYr776quLj4zVmzBidP39eI0eOvKvtlCxZUpI0atQoNWjQQK6uripVqpTq1q0rDw8PtWrVSn369NG1a9c0ceJEnTt3Lt371L17d82ePVtNmzZVv379VKFCBV29elWrVq1S48aNVbNmTbVs2VIzZ85Uw4YN1a1bN1WoUEHu7u46fPiwVqxYoaZNm+rpp59Odw1AlpXRdzcBwL1Kvqt9/fr1aY6bN2+eqVmzpvH39zeenp4mMjLSPPvss2bp0qX2MYcPHzbPPPOMyZEjh/Hz8zP169c3W7duTfFO9fHjx5t8+fIZV1dXh7vIk5KSzOjRo03+/PmNl5eXKV++vFm+fHmqd7V//fXXKda7atUq06hRIxMYGGjc3d1N7ty5TaNGjVIdnyytu9pPnTrlMLZ9+/bG19fXaR3Vq1c3jzzyiFOt06dPN127djUhISHG09PTPP7442bDhg1Oy8+bN89UrFjReHl5GV9fX1O7dm3z66+/OoxJrSZjjImPjzcvv/yyCQkJMTabzUgy+/btM8YYs2DBAlO6dGnj5eVlcufObXr37m2+//57p6cM3L4Pt+5zZGSkw7Rz586Zbt26mbx58xp3d3cTGhpqGjVqZP7++2/7mISEBPPee+/Zt50tWzZTtGhR8+qrr5pdu3Y5bQfAndmMMSbDUi8A4KG0cuVK1axZU19//XWaNz0BwL3gcUoAAACwBMETAAAAluBUOwAAACzBEU8AAABYguAJAAAASxA8AQAAYAkeII8UJSUl6ejRo/Lz87unt7cDAAAZxxijuLg4hYeHy8Xl4Tu+SPBEio4ePaqIiIiMLgMAAKTDoUOHlCdPnowuwwnBEyny8/OTJO3bt0+BgYEZXE3GS0hI0I8//qh69erJ3d09o8t5KNATZ/TEGT1xRD+c0RNn/6QnFy9eVEREhP33+MOG4IkUJZ9e9/Pzk7+/fwZXk/ESEhLk4+Mjf39/fjD+f/TEGT1xRk8c0Q9n9MTZ/ejJw3qZ3MN38h8AAACZEsETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCXcMroAPNwqjlimRDffjC4jw3m6Go2uIJWI+UHxN2wZXc5DgZ44oyfO6Ikj+uHsYe7J/pGNMrqETIcjngAAALAEwRMAAACWIHgCAADAEhkaPGvUqKHu3btnZAkO9u/fL5vNps2bN2d0KfdVbGyssmfPntFlAADwr3TkyBE9//zzCgoKko+Pj8qUKaONGzfa53fo0EE2m83ho1KlSg7rqFGjhtOYli1bpri9+Ph4de/eXR4eHilmktjYWJUqVUpeXl4KCwtTly5d0qw/Pj5eb7zxhoKDg+Xr66snn3xShw8fdhhz7tw5tW3bVgEBAQoICFDbtm11/vz5f7zt23FzEQAAQCrOnTunqlWrqmbNmvr+++8VGhqqPXv2OB3QqV+/vqZOnWp/7eHh4bSujh076p133rG/9vb2TnGb/fv3V2BgoPbv3+80b9y4cRo7dqzGjBmjihUr6tq1a9q7d2+a+9C9e3ctWLBAs2bNUlBQkHr27KnGjRtr48aNcnV1lSS1bt1ahw8f1uLFiyVJr7zyitq2basFCxb8o23fjuAJAACQilGjRikiIsIhVEZFRTmN8/T0VFhYWJrr8vHxueOY77//XkuWLFGXLl30+++/O8w7d+6c3nrrLS1YsEC1a9e2T3/kkUdSXd+FCxc0ZcoUTZ8+XXXq1JEkzZgxQxEREVq6dKmio6O1fft2LV68WGvXrlXFihUlSZMmTVLlypW1Y8cOFSlSJF3bTslDc43njBkzVL58efn5+SksLEytW7fWyZMn7fNTOl08b9482Wz/e/RCTEyMypQpo+nTpysqKkoBAQFq2bKl4uLi7GOSkpI0atQoFSxYUJ6ensqbN6+GDRvmsN69e/eqZs2a8vHxUenSpbVmzZq72ocDBw6oSZMmypEjh3x9ffXII49o0aJFkqSVK1fKZrPpu+++U+nSpeXl5aWKFStqy5YtDutYvXq1nnjiCXl7eysiIkJdu3bV5cuX7fOvX7+uPn36KHfu3PL19VXFihW1cuVKh3XExsYqb9688vHx0dNPP60zZ87cVf0AAMDR/PnzVb58eTVv3lyhoaEqW7asJk2a5DRu5cqVCg0NVeHChdWxY0eHDJNs5syZCg4O1iOPPKJevXo55BNJOnHihDp27KjY2NgUj5guWbJESUlJOnLkiIoVK6Y8efKoRYsWOnToUKr1b9y4UQkJCapXr559Wnh4uEqUKKHVq1dLktasWaOAgAB76JSkSpUqKSAgwD4mPdtOyUMTPK9fv66hQ4fqjz/+0Lx587Rv3z516NDhntezZ88ezZs3TwsXLtTChQu1atUqjRw50j6/f//+GjVqlAYNGqRt27bpiy++UM6cOR3WMXDgQPXq1UubN29W4cKF1apVKyUmJt5x26+//rri4+P1008/acuWLRo1apSyZcvmMKZ379567733tH79eoWGhurJJ59UQkKCJGnLli2Kjo5Ws2bN9Oeff2r27Nn65ZdfHK6feOGFF/Trr79q1qxZ+vPPP9W8eXPVr19fu3btkiT99ttvevHFF9W5c2dt3rxZNWvW1LvvvnvPfQQAADcPRk2cOFGFChXSDz/8oE6dOqlr166aNm2afUyDBg00c+ZMLV++XGPHjtX69etVq1YtxcfH28e0adNGX375pVauXKlBgwZpzpw5atasmX2+MUYdOnRQp06dVK5cuVRrSUpK0vDhwzV+/Hh98803Onv2rOrWravr16+nuMzx48fl4eGhHDlyOEzPmTOnjh8/bh8TGhrqtGxoaKh9THq2nZKH5lT7iy++aP88f/78+vDDD1WhQgVdunTJKbylJSkpSbGxsfLz85MktW3bVsuWLdOwYcMUFxenDz74QB999JHat28vSSpQoICqVavmsI5evXqpUaObD40dMmSIHnnkEe3evVtFixZNc9sHDx7UM888o5IlS9r343aDBw9W3bp1JUn//e9/lSdPHn377bdq0aKFxowZo9atW9tvuCpUqJA+/PBDVa9eXRMnTtSRI0f05Zdf6vDhwwoPD7fXunjxYk2dOlXDhw/XBx98oOjoaPXr10+SVLhwYa1evdp+zUZq4uPjHf6DXLx4UZLk6WLk6mrSXDYr8HQxDv+CnqSEnjijJ47oh7OHuScJCQlKSkpSuXLlNGTIEElSiRIltGXLFn3yySdq1aqVJDkEyCJFiqh06dIqWLCg/u///k9PP/20JDkcTCtSpIjy5cunSpUqad26dSpbtqw++ugjXbhwQb169bIfkEquIfl18ufjxo1TrVq1JEnTpk1TRESElixZonr16jksmxZjjMNZ41s/T2lMUlKSEhIS9OGHH9qPnn755ZcKCwvTihUrFB0dfVfbfWiC56ZNmxQTE6PNmzfr7NmzSkpKknQzzBUvXvyu1xMVFWUPnZKUK1cu++Hu7du3Kz4+3uHahJSUKlXKYXlJOnny5B2DZ9euXfXaa6/pxx9/VJ06dfTMM884rEuSKleubP88MDBQRYoU0fbt2yXdPBy+e/duzZw50z7GGKOkpCTt27dPW7dulTFGhQsXdlhnfHy8goKC7PuY/E1+6zbvFDxHjBhh/091q7fKJsnH50aay2YlQ8snZXQJDx164oyeOKMnjuiHs4exJ4sWLVL27NmVLVs2+6VzkpSYmKhdu3Y5TLtdcHCwvvvuO3l6eqY43xgjNzc3ff311zp27JhmzZqlDRs2yNfX8d0CK1WqpOrVq6tbt246deqUJOnYsWMO2/bz89OiRYuUmJioK1euOCwfFham69ev69y5cw5HPU+ePKkqVarYx5w4ccKpxlOnTtnPCifnoVszWUhIiIKDg3Xw4MFU+3C7hyJ4Xr58WfXq1VO9evU0Y8YMhYSE6ODBg4qOjrYfvnVxcZExjn8NpZTq3d3dHV7bbDZ7iE3t7rG01nFr0r+Tl19+WdHR0fruu+/0448/asSIERo7dqzeeOONNJe7dRuvvvqqunbt6jQmb968+vPPP+Xq6upwF1qy5KPCt/fobvXv3189evSwv7548aIiIiL07iYXJbq7prFk1uDpYjS0fJIGbXBRfNLD9ZZuGYWeOKMnzuiJI/rh7GHuydaYaNWqVUuHDx9Ww4YN7dOXL1+uwoULO0y71ZkzZ3T27FlVr1491TFbt25VYmKiGjRooMcff1wlSpSwn21MTEzUd999pyFDhuiLL75QhQoVlCdPHhUsWFATJkxQnjx57Ec8z549q7i4ODVq1Eh169a1ryNZuXLl5O7uriVLlqhFixaSbgbXrVu3avTo0ZJuHqC6cOGC1q1bpwoVKki6eenehQsX7OG0atWqkqQdO3YoT5489m2fPn1akZGRd93ThyJ4/v333zp9+rRGjhypiIgISdKGDRscxoSEhCguLk6XL1+2/zVwr8/bLFSokLy9vbVs2TK9/PLL96X220VERKhTp07q1KmT+vfvr0mTJjkEz7Vr1ypv3rySbt6dtnPnTvuR1EcffVR//fWXChYsmOK6y5Ytqxs3bujkyZN6/PHHUxxTvHhxrV271mHa7a9T4unpmeJfZfFJNiU+ZO+dm5Hik2wP3XsJZzR64oyeOKMnjuiHs4exJ+7u7urZs6eqVKmiMWPGqEWLFlq3bp0mT56szz//XO7u7rp06ZJiYmL0zDPPKFeuXNq/f78GDBig4OBgNW/eXO7u7tqzZ49mzpyphg0bKjg4WNu2bVPPnj1VtmxZVa9eXa6uripQoIB9uwkJCdq0aZOk/52Wl27eQd60aVP17NlTn3/+ufz9/dW/f38VLVpUdevWlbu7u/2o6MaNG1WzZk0FBATopZdeUs+ePRUUFKTAwED16tVLJUuWtN/lXqxYMdWvX18dO3bUZ599Junm45QaN26sIkWKSLp56V7Tpk3VrVs3p23XrFnzrnv6UNxclDdvXnl4eGjChAnau3ev5s+fr6FDhzqMqVixonx8fDRgwADt3r1bX3zxhWJjY+9pO15eXurbt6/69OmjadOmac+ePVq7dq2mTJlyX/aje/fu+uGHH7Rv3z79/vvvWr58uYoVK+Yw5p133tGyZcu0detWdejQQcHBwXrqqackSX379tWaNWv0+uuva/Pmzdq1a5fmz59vD66FCxdWmzZt1K5dO82dO1f79u3T+vXrNWrUKPsh965du2rx4sUaPXq0du7cqY8++uiOp9kBAEDKHnvsMX377bf68ssvVaJECQ0dOlTjx49XmzZtJEmurq7asmWLmjZtqsKFC6t9+/YqXLiw1qxZY7/0z8PDQ8uWLVN0dLSKFCmirl27ql69elq6dKnTGcw7mTZtmipWrKhGjRqpevXqcnd31+LFi+1na5PPBt96yv3999/XU089pRYtWqhq1ary8fHRggULHLY9c+ZMlSxZ0n4GulSpUpo+ffo9bftuPBRHPENCQhQbG6sBAwboww8/1KOPPqr33ntPTz75pH1MYGCgZsyYod69e+vzzz9XnTp1FBMTo1deeeWetjVo0CC5ubnp7bff1tGjR5UrVy516tTpvuzHjRs39Prrr+vw4cPy9/dX/fr19f777zuMGTlypLp166Zdu3apdOnSmj9/vv2RCaVKldKqVas0cOBAPf744zLGqECBAnruuefsy0+dOlXvvvuuevbsqSNHjigoKEiVK1e2H8qvVKmSJk+erMGDBysmJkZ16tTRW2+95RTkAQDA3WncuLEaN26c4jxvb2/98MMPaS4fERGhVatW3dM2c+bMqevXrzuFOn9/f02ZMiXVg2bJp71vPTPq5eWlCRMmaMKECaluLzlnpeVO274bNpPeiwJxT1auXKmaNWvq3Llz/4q3r7x48aICAgJUoOdsJbr53nmBTM7T1Wh0hRvqs871oTsVlFHoiTN64oyeOKIfzh7mnuwf2ShDtpuQkKBFixapYcOG93Q0Ufrf7+8LFy7I39//AVWYfg/FqXYAAABkfgTPe9CgQQNly5YtxY/hw4dndHkAAAAPtYfiGs9/i8mTJ+vq1aspzgsMDExz2Ro1aqT7UUcAAACZAcHzHuTOnTujS7Dcb/1r2x9On5UlX2+zNSb6nq+3yazoiTN64oyeOKIfzuhJ1sKpdgAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWuG/B8/z58/drVQAAAMiE0hU8R40apdmzZ9tft2jRQkFBQcqdO7f++OOP+1YcAAAAMo90Bc/PPvtMERERkqQlS5ZoyZIl+v7779WgQQP17t37vhYIAACAzMEtPQsdO3bMHjwXLlyoFi1aqF69eoqKilLFihXva4EAAADIHNJ1xDNHjhw6dOiQJGnx4sWqU6eOJMkYoxs3bty/6gAAAJBppOuIZ7NmzdS6dWsVKlRIZ86cUYMGDSRJmzdvVsGCBe9rgQAAAMgc0hU833//fUVFRenQoUMaPXq0smXLJunmKfjOnTvf1wIBAACQOaQreLq7u6tXr15O07t37/5P6wEAAEAmle7neE6fPl3VqlVTeHi4Dhw4IEkaP368/u///u++FQcAAIDMI13Bc+LEierRo4caNGig8+fP228oyp49u8aPH38/6wMAAEAmka7gOWHCBE2aNEkDBw6Uq6urfXr58uW1ZcuW+1YcAAAAMo90Bc99+/apbNmyTtM9PT11+fLlf1wUAAAAMp90Bc98+fJp8+bNTtO///57FS9e/J/WBAAAgEwoXXe19+7dW6+//rquXbsmY4zWrVunL7/8UiNGjNDkyZPvd40AAADIBNIVPF944QUlJiaqT58+unLlilq3bq3cuXPrgw8+UMuWLe93jQAAAMgE7jl4JiYmaubMmWrSpIk6duyo06dPKykpSaGhoQ+iPgAAAGQS93yNp5ubm1577TXFx8dLkoKDgwmdAAAAuKN03VxUsWJFbdq06X7XAgAAgEwsXdd4du7cWT179tThw4dVrlw5+fr6OswvVarUfSkOGa/iiGVKdPO988BMztPVaHQFqUTMD4q/Ycvoch4K9MQZPXFGTxxl5X7sH9koo0vAQyBdwfO5556TJHXt2tU+zWazyRgjm81mfycjAAAAIFm6gue+ffvudx0AAADI5NJ1jWdkZGSaHwAAALeLiYmRzWZz+IiIiLDPv3Tpkrp06aI8efLI29tbxYoV08SJEx3WsWfPHj399NMKCQmRv7+/WrRooRMnTjiMiYqKctpOv3797PPPnDmj+vXrKzw8XJ6enoqIiFCXLl108eLFNOuPj4/XG2+8oeDgYPn6+urJJ5/U4cOHncZ99913qlixory9vRUcHKxmzZrZ58XGxjrVlvxx8uTJe+rnv1G6jnhOmzYtzfnt2rW753XWqFFDZcqU0fjx49NT0n23f/9+5cuXT5s2bVKZMmUyupxU/VvqBABAkh555BEtXbrU/jopKUnr16+XJL355ptasWKFZsyYoaioKP3444/q3LmzwsPD1bRpU12+fFn16tVT6dKltXz5cknSoEGD1KRJE61du1YuLv87nvbOO++oY8eO9tfZsmWzf+7i4qKmTZvq3XffVUhIiHbv3q3XX39dZ8+e1RdffJFq7d27d9eCBQs0a9YsBQUFqWfPnmrcuLE2btwoV1dXSdKcOXPUsWNHDR8+XLVq1ZIxRlu2bLGv47nnnlP9+vUd1tuhQwddu3YtSzwlKF3Bs1u3bg6vExISdOXKFXl4eMjHxyddwRMAAGR+bm5uCgsLs79OSEiwf75mzRq1b99eNWrUkCS98sor+uyzz7RhwwY1bdpUv/76q/bv369NmzbJ399fkjR16lQFBgZq+fLlqlOnjn1dfn5+Dtu5VY4cOfTaa6/ZX0dGRqpz584aM2ZMqnVfuHBBU6ZM0fTp0+3bmTFjhiIiIrR06VJFR0crMTFR3bp105gxY/TSSy/Zly1SpIj9c29vb3l7e9tfnzp1SsuXL9eUKVPS7Ftmka5T7efOnXP4uHTpknbs2KFq1arpyy+/vN81AgCATGLXrl0KDw9Xvnz51LJlS+3du9c+r1q1apo/f76OHDkiY4xWrFihnTt3Kjo6WtLNU902m02enp72Zby8vOTi4qJffvnFYTujRo1SUFCQypQpo2HDhun69eup1nT06FHNnTtX1atXT3XMxo0blZCQoHr16tmnhYeHq0SJElq9erUk6ffff9eRI0fk4uKismXLKleuXGrQoIH++uuvVNc7bdo0+fj46Nlnn011TGaSruCZkkKFCmnkyJFOR0PTY8aMGSpfvrz9r5XWrVs7XPcQGxur7NmzOywzb9482Wz/ezRFTEyMypQpo+nTpysqKkoBAQFq2bKl4uLi7GOSkpI0atQoFSxYUJ6ensqbN6+GDRvmsN69e/eqZs2a8vHxUenSpbVmzZq72oczZ86oVatWypMnj3x8fFSyZEmnUF6jRg117dpVffr0UWBgoMLCwhQTE+Mw5u+//1a1atXk5eWl4sWLa+nSpbLZbJo3b16q2962bZsaNmyobNmyKWfOnGrbtq1Onz59V3UDAPCgVKxYUdOmTdMPP/ygSZMm6fjx46pevbr92soPP/xQxYsXV548eeTh4aH69evrk08+UbVq1SRJlSpVkq+vr/r27asrV67o8uXL6t27t5KSknTs2DH7drp166ZZs2ZpxYoV6tKli8aPH6/OnTs71dOqVSv5+Pgod+7c8vf31+TJk1Ot/fjx4/Lw8FCOHDkcpufMmVPHjx+XJHuIjomJ0VtvvaWFCxcqR44cql69us6ePZviev/zn/+odevWDkdBM7N0nWpPjaurq44ePfqP13P9+nUNHTpURYoU0cmTJ/Xmm2+qQ4cOWrRo0T2tZ8+ePZo3b54WLlyoc+fOqUWLFho5cqQ9XPbv31+TJk3S+++/r2rVqunYsWP6+++/HdYxcOBAvffeeypUqJAGDhyoVq1aaffu3XJzS7t1165dU7ly5dS3b1/5+/vru+++U9u2bZU/f35VrFjRPu6///2vevTood9++01r1qxRhw4dVLVqVdWtW1dJSUl66qmnlDdvXv3222+Ki4tTz54909zusWPHVL16dXXs2FHjxo3T1atX1bdvX7Vo0cJ+PUxK4uPj7e9GJcn+Q8DTxcjV1aS5zazA08U4/At6khJ64oyeOMrK/UhISHA4FV60aFGVL19eRYoU0YoVK/TMM89owoQJWrNmjebOnau8efPql19+UefOnRUSEqLatWsre/bs+vLLL/XGG2/oww8/lIuLi5577jmVLVtWNpvNftq+S5cu9u0UK1ZMfn5+atmypd59910FBQXZ540ePVoDBgzQzp07NWjQIHXv3l0TJkxIsf7ExET7ftwqKSlJxhglJCTYj6r269dPTz75pCTp888/V758+TRr1iyHa04lae3atdq2bZv+85//OKw3+fPbt3U30rOMldIVPOfPn+/w2hijY8eO6aOPPlLVqlX/cVEvvvii/fP8+fPrww8/VIUKFXTp0iWHi4PvJCkpSbGxsfLz85MktW3bVsuWLdOwYcMUFxenDz74QB999JHat28vSSpQoID9r6pkvXr1UqNGNx96O2TIED3yyCPavXu3ihYtmua2c+fOrV69etlfv/HGG1q8eLG+/vprh+BZqlQpDR48WNLNo8YfffSRli1bprp16+rHH3/Unj17tHLlSvt1KsOGDVPdunVT3e7EiRP16KOPavjw4fZp//nPfxQREaGdO3eqcOHCKS43YsQIDRkyxGn6W2WT5OPDc1mTDS2flNElPHToiTN64oyeOMqK/Ujt4FGuXLl07NgxLVy4UG+99Zb69esnFxcXHT58WFFRUapUqZIGDBhg/10pSePGjdPFixfl4uKibNmyqUOHDipVqlSq27h8+bIkafr06Sn+HnRzc1Pbtm01YMAAVaxYUYGBgU5jDhw4oOvXr+urr75yyCJ79uxRcHCwFi1apIMHD0qSzp8/71BLjhw5tGLFCuXOndthnRMmTFC+fPl0/PjxFGtfsmRJivuTlitXrtzzMlZKV/B86qmnHF7bbDaFhISoVq1aGjt27D8uatOmTYqJidHmzZt19uxZJSXd/A968OBBFS9e/K7XExUVZQ+d0s1v7uRT9tu3b1d8fLxq166d5jpufRemXLlySZJOnjx5x+B548YNjRw5UrNnz9aRI0fsRxTv9C5Pt9a4Y8cORUREOFwcXaFChTS3u3HjRq1YsSLFgL5nz55Ug2f//v3Vo0cP++uLFy8qIiJC725yUaK7a5rbzAo8XYyGlk/SoA0uik/KWu82khp64oyeOKMnjrJyP7bGRDtNi4+PV+fOnVW8eHE98cQTSkxMVIUKFRzu+l64cKEkqWHDhimud8WKFbpw4YJ69erlcBPPrb777jtJUrNmzZQ3b94UxyTfrFStWjVFRUU5za9ataqGDh0qm81mr+XYsWM6ePCgPvroI9WrV0/VqlWzH1VNHpOQkKALFy6oVq1aDvtw6dIlPf/883r33Xed9i0hIUFLlixR3bp15e7unmK9qbnTI6EyWrqCZ3IQfBCSH5VQr149zZgxQyEhITp48KCio6Pth7BdXFxkjONpipQOLd/+xbLZbPba7/ZailvXkXwN6d3s/9ixY/X+++9r/PjxKlmypHx9fdW9e3eni5vTqjH5naDuRVJSkpo0aaJRo0Y5zUsOzinx9PR0uFg7WXySTYlZ7G3d0hKfZMtyb3N3J/TEGT1xRk8cZcV+uLu7q1evXmrSpIny5s2rkydP6t1331VcXJxq1qypoKAgVa9eXf3795efn58iIyO1atUqzZgxQ+PGjbP/vpw6daqKFSumkJAQrVmzRt26ddObb76pEiVKSLp5Z/zatWtVs2ZNBQQEaP369XrzzTf15JNPqkCBApJuHn09ceKEHnvsMWXLlk3btm1Tnz59VLVqVRUqVEiSdOTIEdWuXVvTpk1ThQoVFBwcrJdeekl9+/ZVzpw5FRgYqF69eqlkyZKqX7++XF1dFRQUpE6dOumdd95RVFSUIiMj7XfKt2zZ0uF3/ty5c5WYmKh27dqlGi7d3d3vOXje63irpSt4vvPOO+rVq5d8fHwcpl+9elVjxozR22+/ne6C/v77b50+fVojR460P1R2w4YNDmNCQkIUFxeny5cv248gbt68+Z62U6hQIXl7e2vZsmV6+eWX011van7++Wc1bdpUzz//vKSbgXDXrl0qVqzYXa+jaNGiOnjwoE6cOKGcOXNKkv1ZZ6l59NFHNWfOHEVFRd3xOlQAAKx0+PBhtWrVSqdPn1ZISIgqVaqkn3/+Wfv375ckzZo1S/3791ebNm109uxZRUZGatiwYerUqZN9HTt27FD//v119uxZRUVFaeDAgXrzzTft8z09PTV79mwNGTJE8fHxioyMVMeOHdWnTx/7GG9vb02aNElvvvmm4uPjFRERoWbNmjk8ZD4hIUE7duxwOHX9/vvvy83NTS1atNDVq1dVu3ZtxcbG2p/hKUljxoyxn7q/evWqKlasqOXLlzvdlDRlyhQ1a9bMaXpml65kMmTIEHXq1MkpeF65ckVDhgz5R8Ezb9688vDw0IQJE9SpUydt3bpVQ4cOdRhTsWJF+fj4aMCAAXrjjTe0bt06xcbG3tN2vLy81LdvX/Xp00ceHh6qWrWqTp06pb/++svh2VvpVbBgQc2ZM0erV69Wjhw5NG7cOB0/fvyegmfdunVVoEABtW/fXqNHj1ZcXJwGDhwoSakeCX399dc1adIktWrVSr1791ZwcLB2796tWbNmadKkSQ7/OQAAsNKsWbOcpiUkJNiDZ1hYmKZOnZrmOkaOHKmRI0emOv/RRx/V2rVr01xHzZo17Y9ASk1UVJTT2VUvLy9NmDAh1RuQpJtHHN977z299957aa7/TtvPrNL1OKXUTgH/8ccfKV6Qey9CQkIUGxurr7/+WsWLF9fIkSOdvniBgYGaMWOGFi1aZH9M0e2PIbobgwYNUs+ePfX222+rWLFieu655+7b21UNGjRIjz76qKKjo1WjRg2FhYU5XRt7J66urpo3b54uXbqkxx57TC+//LLeeustSTe/+VMSHh6uX3/9VTdu3FB0dLRKlCihbt26KSAgwOEdHQAAAKxmM7fH+TTkyJFDNptNFy5ckL+/v0P4vHHjhi5duqROnTrp448/fiDFQvr1119VrVo17d69236tyoNw8eJFBQQEqEDP2Up0873zApmcp6vR6Ao31Geda5a7Lis19MQZPXFGTxxl5X7sH9koxekJCQlatGiRGjZs+NBfn2iVf9KT5N/fyVntYXNPp9rHjx8vY4xefPFFDRkyRAEBAfZ5Hh4eioqKUuXKle97kVnZt99+q2zZsqlQoULavXu3unXrpqpVqz7Q0AkAAPAg3FPwTH7eZb58+VSlSpUs/ZdJgwYN9PPPP6c4b8CAARowYMB92U5cXJz69OmjQ4cOKTg4WHXq1Lkvj6wCAACwWrpuLrr1vUyvXr3q9Cijh/HQ7v02efJkXb16NcV5//Q611u1a9dO7dq1u2/ru1e/9a/t8C4PWVXyaY+tMdFZ+g+uW9ETZ/TEGT1xRD+Q1aUreF65ckV9+vTRV199pTNnzjjNv3Ej87/Tze3vPgAAAIC0pes25969e2v58uX65JNP5OnpqcmTJ2vIkCEKDw/XtGnT7neNAAAAyATSdcRzwYIFmjZtmmrUqKEXX3xRjz/+uAoWLKjIyEjNnDlTbdq0ud91AgAA4F8uXUc8z549q3z58km6eT3n2bNnJd18f9Offvrp/lUHAACATCNdwTN//vz2dxkoXry4vvrqK0k3j4Rmz579ftUGAACATCRdwfOFF17QH3/8IUnq37+//VrPN998U717976vBQIAACBzSNc1nm+++ab985o1a+rvv//Whg0bVKBAAZUuXfq+FQcAAIDMI13B81bXrl1T3rx5lTdv3vtRDwAAADKpdJ1qv3HjhoYOHarcuXMrW7Zs2rt3ryRp0KBBmjJlyn0tEAAAAJlDuoLnsGHDFBsbq9GjR8vDw8M+vWTJkpo8efJ9Kw4AAACZR7qC57Rp0/T555+rTZs2cnV1tU8vVaqU/v777/tWHAAAADKPdAXPI0eOqGDBgk7Tk5KSnN63HQAAAJDSGTwfeeQR/fzzz07Tv/76a5UtW/YfFwUAAIDMJ113tQ8ePFht27bVkSNHlJSUpLlz52rHjh2aNm2aFi5ceL9rBAAAQCZwT0c89+7dK2OMmjRpotmzZ2vRokWy2Wx6++23tX37di1YsEB169Z9ULUCAADgX+yejngWKlRIx44dU2hoqKKjo/Wf//xHu3fvVlhY2IOqDwAAAJnEPR3xNMY4vP7+++915cqV+1oQAAAAMqd03VyU7PYgCgAAAKTmnoKnzWaTzWZzmgYAAADcyT1d42mMUYcOHeTp6Snp5vu0d+rUSb6+vg7j5s6de/8qBAAAQKZwT8Gzffv2Dq+ff/75+1oMAAAAMq97Cp5Tp059UHUAAAAgk/tHNxcBAAAAd4vgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJt4wuAA+3iiOWKdHNN6PLyHCerkajK0glYn5Q/A1bquP2j2xkYVUAAPy7cMQTAAAAliB4AgAAwBIETwAAAFiC4JkJREVFafz48RldBm7x008/qUmTJgoPD5fNZtO8efMc5s+dO1fR0dEKDg6WzWbT5s2bHeafPXtWb7zxhooUKSIfHx/lzZtXXbt21YULF+xjVq5cKZvNluLH+vXr7eNSmv/pp5+mWX+NGjWclmnZsmWKY+Pj41WmTBmn/YiNjU21vpMnT95dIwEAmQo3FwEPwOXLl1W6dGm98MILeuaZZ1KcX7VqVTVv3lwdO3Z0mn/06FEdPXpU7733nooXL64DBw6oU6dOOnr0qL755htJUpUqVXTs2DGH5QYNGqSlS5eqfPnyDtOnTp2q+vXr218HBATccR86duyod955x/7a29s7xXH9+/dXeHi4/vjjD4fpzz33nMM2JalDhw66du2aQkND77h9AEDmkyWD5/Xr1+Xh4ZHRZSATa9CggRo0aJDq/LZt20qS9u/fn+L8EiVKaM6cOfbXBQoU0LBhw/T8888rMTFRbm5u8vDwUFhYmH1MQkKC5s+fry5dushmc7zzPnv27A5j74aPj88dl9m4caOWLFmiuXPn6vvvv3eY5+3t7RBWT506peXLl2vKlCn3VAcAIPP415xq/+abb1SyZEl5e3srKChIderU0eXLl9WhQwc99dRTGjJkiEJDQ+Xv769XX31V169fty9bo0YNdenSRT169FBwcLDq1q0rSRo3bpxKliwpX19fRUREqHPnzrp06ZKkm0ek/P397UeXki1YsEC+vr6Ki4u7Y819+/ZV4cKF5ePjo/z582vQoEFKSEiwz4+JiVGZMmU0ffp0RUVFKSAgQC1btnRYd1xcnNq0aSNfX1/lypVL77//vmrUqKHu3bunut0LFy7olVdesfejVq1aTkej8O9z4cIF+fv7y80t5b8X58+fr9OnT6tDhw5O87p06aLg4GA99thj+vTTT5WUlHTH7c2cOVPBwcF65JFH1KtXL6fv+RMnTuiTTz5RbGysfHx87ri+adOmycfHR88+++wdxwIAMqd/xRHPY8eOqVWrVho9erSefvppxcXF6eeff5YxRpK0bNkyeXl5acWKFdq/f79eeOEFBQcHa9iwYfZ1/Pe//9Vrr72mX3/91b6ci4uLPvzwQ0VFRWnfvn3q3Lmz+vTpo08++US+vr5q2bKlpk6d6vCLMvm1n5/fHev28/NTbGyswsPDtWXLFnXs2FF+fn7q06ePfcyePXs0b948LVy4UOfOnVOLFi00cuRIe+09evTQr7/+qvnz5ytnzpx6++239fvvv6tMmTIpbtMYo0aNGikwMFCLFi1SQECAPvvsM9WuXVs7d+5UYGBgisvFx8crPj7e/vrixYuSJE8XI1dXc8d9zew8XYzDv6m59Q+LWyUmJqY4L3laQkJCqstK0pkzZzR06FC9/PLLqY6bPHmy6tWrp7CwMKc/cGrVqmX/P9KzZ0+dOHFCAwYMSHV7LVu2VFRUlHLmzKm//vpLgwYN0ubNm+1HNY0xevHFFxUdHa1SpUrpyJEjd9yPKVOmqGXLlnJzc0tzX//Nbv164iZ64oh+OKMnzv5JTx72PtpMcgp7iP3+++8qV66c9u/fr8jISId5HTp00IIFC3To0CH7UZdPP/1UvXv31oULF+Ti4qIaNWrowoUL2rRpU5rb+frrr/Xaa6/p9OnTkqR169apSpUqOnjwoMLDw3X69GmFh4dryZIlql69+j3vx5gxYzR79mxt2LBB0s1AMGbMGB0/ftweZPv06aOffvpJa9euVVxcnIKCgvTFF1/Yw++FCxcUHh6ujh072m8oioqKUvfu3dW9e3ctX75cTz/9tE6ePClPT0/7tgsWLKg+ffrolVdeSbG2mJgYDRkyxGn6F198cVdHs5C6p556Sv369VOlSpWc5p04cUKvvvqqxo0bp/z586e4/JUrVxQTE6Ns2bJpwIABKR7xPH36tF555RX16tVLVapUSbOeefPm6auvvtIXX3xx1/uwe/du9erVS2PHjlWBAgW0cOFC/fLLLxo2bJhcXV3vuB9///23+vXrp/fee08FCxa86+0CAO7NlStX1Lp1a/tZsofNv+KIZ+nSpVW7dm2VLFlS0dHRqlevnp599lnlyJHDPv/WcFS5cmVdunRJhw4dsgfV22+2kKQVK1Zo+PDh2rZtmy5evKjExERdu3ZNly9flq+vrypUqKBHHnlE06ZNU79+/TR9+nTlzZtXTzzxxF3V/c0332j8+PHavXu3Ll26pMTERKdvgqioKIejp7ly5bLf8bt3714lJCSoQoUK9vkBAQEqUqRIqtvcuHGjLl26pKCgIIfpV69e1Z49e1Jdrn///urRo4f99cWLFxUREaF3N7ko0d31rvY3M/N0MRpaPkmDNrgoPin1dy7aGhOd4vRy5cqpYcOGTtOTr/GsVq1aikex4+Li1KhRI+XJk0fz5s2Tl5dXiusfNmyYgoKCNHjwYLm7u6e5L9mzZ1dsbKzKlSunnDlzpjk2mTFG/fv3V86cOdWwYUNNmTJFO3fuVPPmzR2uJ+3du7datWql//znPw7Lz5s3T6VLl1bXrl3vanv/VgkJCVqyZInq1q17x69DVkFPHNEPZ/TE2T/pSfIZy4fVvyJ4urq6asmSJVq9erV+/PFHTZgwQQMHDtRvv/2W5nK3/kL09XV828cDBw6oYcOG6tSpk4YOHarAwED98ssveumllxwOU7/88sv66KOP1K9fP02dOlUvvPCC040bKVm7dq1atmypIUOGKDo6WgEBAZo1a5bGjh3rMO72byibzWa//i75YPTt20vrIHVSUpJy5cqllStXOs3Lnj17qst5eno6HCFNFp9kU2IabxGZ1cQn2dJ8y8zUfkC4ubmlOC95mru7u9P8ixcvqlGjRvL09NSCBQtSPfJsjNG0adPUrl27uzo6vWXLFnl5eSkkJOSuf6Bt3bpVCQkJioiIkLu7uz766CMNGTJEP//8sx5//HGdOnVK0dHRmj17tipWrOiw3kuXLumbb77RiBEjsswvlZS+nlkdPXFEP5zRE2fp6cnD3sN/RfCUboavqlWrqmrVqnr77bcVGRmpb7/9VpL0xx9/6OrVq/Y7aNeuXats2bIpT548qa5vw4YNSkxM1NixY+XicvMeq6+++spp3PPPP68+ffroww8/1F9//aX27dvfVb2//vqrIiMjNXDgQPu0AwcO3PX+SjfvZHZ3d9e6desUEREh6WYY2bVrV6qn+h999FEdP35cbm5uioqKuqft4f65dOmSdu/ebX+9b98+bd68WYGBgcqbN6/Onj2rgwcP6ujRo5KkHTt2SJLCwsIUFhamuLg41atXT1euXNGMGTN08eJF+1+xISEhcnX931Ho5cuXa9++fXrppZec6liwYIGOHz+uypUry9vbWytWrNDAgQP1yiuv2P/QOHLkiGrXrq1p06apQoUK2rNnj2bOnKmGDRsqODhY27ZtU8+ePVW2bFlVrVpVkpQ3b17lypVLBw8eVIkSJezXeBYoUMDp/93s2bOVmJioNm3a3K/2AgD+pf4VwfO3337TsmXLVK9ePYWGhuq3337TqVOnVKxYMf3555+6fv26XnrpJb311ls6cOCABg8erC5dutgDZUoKFCigxMRETZgwQU2aNNGvv/6a4kO1c+TIoWbNmql3796qV69emmH2VgULFtTBgwc1a9YsPfbYY/ruu+/sQflu+fn5qX379urdu7cCAwMVGhqqwYMHy8XFJdWjrnXq1FHlypX11FNPadSoUSpSpIiOHj2qRYsW6amnnkrxkgPcfxs2bFDNmjXtr5MvY2jfvr1iY2M1f/58vfDCC/b5yQ9nHzx4sGJiYrRx40b7Ef3br4nct2+fwx8VU6ZMUZUqVVSsWDGnOtzd3fXJJ5+oR48eSkpKUv78+fXOO+/o9ddft49JSEjQjh07dOXKFUmSh4eHli1bpg8++ECXLl1SRESEGjVqpMGDBzsE3rs1ZcoUNWvWzH5pDAAg6/pXBE9/f3/99NNPGj9+vC5evKjIyEiNHTtWDRo00OzZs1W7dm0VKlRITzzxhOLj49WyZUvFxMSkuc4yZcpo3LhxGjVqlPr3768nnnhCI0aMULt27ZzGvvTSS/riiy/04osv3nXNTZs21ZtvvqkuXbooPj5ejRo10qBBg+5Y1+3GjRunTp06qXHjxvL391efPn106NChVK/1s9lsWrRokQYOHKgXX3xRp06dUlhYmJ544om7vp4P/1yNGjXSvCSiQ4cOKT726G6Xv1VaNwnVr1/f6SHut4uKinLYVkREhFatWnVX205tHbdavXr1Pa0LAJB5/Svuak9Lhw4ddP78eae3JLyfZs6cqW7duuno0aMZ/uD5y5cvK3fu3Bo7dmyKp1bvl4sXLyogIEAFes5WopvvnRfI5DxdjUZXuKE+61zTvMZz/8hGFlaVsRISErRo0SI1bNjwob+myCr0xBk9cUQ/nNETZ/+kJ8m/v7mr/V/oypUr2rdvn0aMGKFXX301Q0Lnpk2b9Pfff6tChQq6cOGC/S0MmzZtanktAAAA/8S/5p2LMsLo0aNVpkwZ5cyZU/3793eYN3z4cGXLli3Fj7TeKjE93nvvPZUuXdr+bk0///yzgoOD7+s2AAAAHrR//RHP2NjYB7bumJiYVK/J7NSpk1q0aJHivFvfn/qfKlu2rDZu3Hjf1gcAAJBR/vXBM6MEBgam+vaTmclv/Ws7PYw+K0q+3mZrTDTXIAEAkE6cagcAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCUIngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsATBEwAAAJYgeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETAAAAliB4AgAAwBIETwAAAFiC4AkAAABLEDwBAABgCYInAAAALEHwBAAAgCXcMroAPJyMMZKkuLg4ubu7Z3A1GS8hIUFXrlzRxYsX6cf/R0+c0RNn9MQR/XBGT5z9k55cvHhR0v9+jz9sCJ5I0ZkzZyRJ+fLly+BKAADAvYqLi1NAQEBGl+GE4IkUBQYGSpIOHjz4UH7jWu3ixYuKiIjQoUOH5O/vn9HlPBToiTN64oyeOKIfzuiJs3/SE2OM4uLiFB4e/oCq+2cInkiRi8vNy38DAgL4QXALf39/+nEbeuKMnjijJ47ohzN64iy9PXmYDxhxcxEAAAAsQfAEAACAJQieSJGnp6cGDx4sT0/PjC7loUA/nNETZ/TEGT1xRD+c0RNnmbknNvOw3m8PAACATIUjngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCSeffPKJ8uXLJy8vL5UrV04///xzRpeULj/99JOaNGmi8PBw2Ww2zZs3z2G+MUYxMTEKDw+Xt7e3atSoob/++sthTHx8vN544w0FBwfL19dXTz75pA4fPuww5ty5c2rbtq0CAgIUEBCgtm3b6vz58w5jDh48qCZNmsjX11fBwcHq2rWrrl+//iB2O1UjRozQY489Jj8/P4WGhuqpp57Sjh07HMZktZ5MnDhRpUqVsj+kuXLlyvr+++/t87NaP243YsQI2Ww2de/e3T4tq/UkJiZGNpvN4SMsLMw+P6v1I9mRI0f0/PPPKygoSD4+PipTpow2btxon5/V+hIVFeX0fWKz2fT6669Lynr9SJMBbjFr1izj7u5uJk2aZLZt22a6detmfH19zYEDBzK6tHu2aNEiM3DgQDNnzhwjyXz77bcO80eOHGn8/PzMnDlzzJYtW8xzzz1ncuXKZS5evGgf06lTJ5M7d26zZMkS8/vvv5uaNWua0qVLm8TERPuY+vXrmxIlSpjVq1eb1atXmxIlSpjGjRvb5ycmJpoSJUqYmjVrmt9//90sWbLEhIeHmy5dujzwHtwqOjraTJ061WzdutVs3rzZNGrUyOTNm9dcunTJPiar9WT+/Pnmu+++Mzt27DA7duwwAwYMMO7u7mbr1q3GmKzXj1utW7fOREVFmVKlSplu3brZp2e1ngwePNg88sgj5tixY/aPkydP2udntX4YY8zZs2dNZGSk6dChg/ntt9/Mvn37zNKlS83u3bvtY7JaX06ePOnwPbJkyRIjyaxYscIYk/X6kRaCJxxUqFDBdOrUyWFa0aJFTb9+/TKoovvj9uCZlJRkwsLCzMiRI+3Trl27ZgICAsynn35qjDHm/Pnzxt3d3cyaNcs+5siRI8bFxcUsXrzYGGPMtm3bjCSzdu1a+5g1a9YYSebvv/82xtwMwC4uLubIkSP2MV9++aXx9PQ0Fy5ceCD7ezdOnjxpJJlVq1YZY+hJshw5cpjJkydn6X7ExcWZQoUKmSVLlpjq1avbg2dW7MngwYNN6dKlU5yXFfthjDF9+/Y11apVS3V+Vu3Lrbp162YKFChgkpKS6MdtONUOu+vXr2vjxo2qV6+ew/R69epp9erVGVTVg7Fv3z4dP37cYV89PT1VvXp1+75u3LhRCQkJDmPCw8NVokQJ+5g1a9YoICBAFStWtI+pVKmSAgICHMaUKFFC4eHh9jHR0dGKj493ODVltQsXLkiSAgMDJdGTGzduaNasWbp8+bIqV66cpfvx+uuvq1GjRqpTp47D9Kzak127dik8PFz58uVTy5YttXfvXklZtx/z589X+fLl1bx5c4WGhqps2bKaNGmSfX5W7Uuy69eva8aMGXrxxRdls9myfD9uR/CE3enTp3Xjxg3lzJnTYXrOnDl1/PjxDKrqwUjen7T29fjx4/Lw8FCOHDnSHBMaGuq0/tDQUIcxt28nR44c8vDwyLC+GmPUo0cPVatWTSVKlJCUdXuyZcsWZcuWTZ6enurUqZO+/fZbFS9ePMv2Y9asWfr99981YsQIp3lZsScVK1bUtGnT9MMPP2jSpEk6fvy4qlSpojNnzmTJfkjS3r17NXHiRBUqVEg//PCDOnXqpK5du2ratGn2WqWs15dk8+bN0/nz59WhQwdJ9ON2bhldAB4+NpvN4bUxxmlaZpGefb19TErj0zPGSl26dNGff/6pX375xWleVutJkSJFtHnzZp0/f15z5sxR+/bttWrVKvv8rNSPQ4cOqVu3bvrxxx/l5eWV6ris1JMGDRrYPy9ZsqQqV66sAgUK6L///a8qVaqUYp2ZuR+SlJSUpPLly2v48OGSpLJly+qvv/7SxIkT1a5dO/u4rNaXZFOmTFGDBg0cjjpKWbcft+OIJ+yCg4Pl6urq9FfRyZMnnf6C+rdLvis1rX0NCwvT9evXde7cuTTHnDhxwmn9p06dchhz+3bOnTunhISEDOnrG2+8ofnz52vFihXKkyePfXpW7YmHh4cKFiyo8uXLa8SIESpdurQ++OCDLNmPjRs36uTJkypXrpzc3Nzk5uamVatW6cMPP5Sbm5u9lqzUk9v5+vqqZMmS2rVrV5b8HpGkXLlyqXjx4g7TihUrpoMHD0rKuj9LJOnAgQNaunSpXn75Zfu0rNyPlBA8Yefh4aFy5cppyZIlDtOXLFmiKlWqZFBVD0a+fPkUFhbmsK/Xr1/XqlWr7Ptarlw5ubu7O4w5duyYtm7dah9TuXJlXbhwQevWrbOP+e2333ThwgWHMVu3btWxY8fsY3788Ud5enqqXLlyD3Q/b2WMUZcuXTR37lwtX75c+fLlc5ifFXuSEmOM4uPjs2Q/ateurS1btmjz5s32j/Lly6tNmzbavHmz8ufPn+V6crv4+Hht375duXLlypLfI5JUtWpVp0ex7dy5U5GRkZKy9s+SqVOnKjQ0VI0aNbJPy8r9SNGDv38J/ybJj1OaMmWK2bZtm+nevbvx9fU1+/fvz+jS7llcXJzZtGmT2bRpk5Fkxo0bZzZt2mR/NNTIkSNNQECAmTt3rtmyZYtp1apVio+3yJMnj1m6dKn5/fffTa1atVJ8vEWpUqXMmjVrzJo1a0zJkiVTfLxF7dq1ze+//26WLl1q8uTJY/njLV577TUTEBBgVq5c6fDYjytXrtjHZLWe9O/f3/z0009m37595s8//zQDBgwwLi4u5scffzTGZL1+pOTWu9qNyXo96dmzp1m5cqXZu3evWbt2rWncuLHx8/Oz/0zMav0w5uajttzc3MywYcPMrl27zMyZM42Pj4+ZMWOGfUxW7MuNGzdM3rx5Td++fZ3mZcV+pIbgCScff/yxiYyMNB4eHubRRx+1P27n32bFihVGktNH+/btjTE3H/kxePBgExYWZjw9Pc0TTzxhtmzZ4rCOq1evmi5dupjAwEDj7e1tGjdubA4ePOgw5syZM6ZNmzbGz8/P+Pn5mTZt2phz5845jDlw4IBp1KiR8fb2NoGBgaZLly7m2rVrD3L3naTUC0lm6tSp9jFZrScvvvii/Xs9JCTE1K5d2x46jcl6/UjJ7cEzq/Uk+XmL7u7uJjw83DRr1sz89ddf9vlZrR/JFixYYEqUKGE8PT1N0aJFzeeff+4wPyv25YcffjCSzI4dO5zmZcV+pMZmjDEZcqgVAAAAWQrXeAIAAMASBE8AAABYguAJAAAASxA8AQAAYAmCJwAAACxB8AQAAIAlCJ4AAACwBMETADKJGjVqqHv37hldBgCkiuAJIEvo0KGDbDab08fu3bvvy/pjY2OVPXv2+7Ku9Jo7d66GDh2aoTWkZeXKlbLZbDp//nxGlwIgg7hldAEAYJX69etr6tSpDtNCQkIyqJrUJSQkyN3d/Z6XCwwMfADV3B8JCQkZXQKAhwBHPAFkGZ6engoLC3P4cHV1lSQtWLBA5cqVk5eXl/Lnz68hQ4YoMTHRvuy4ceNUsmRJ+fr6KiIiQp07d9alS5ck3TyS98ILL+jChQv2I6kxMTGSJJvNpnnz5jnUkT17dsXGxkqS9u/fL5vNpq+++ko1atSQl5eXZsyYIUmaOnWqihUrJi8vLxUtWlSffPJJmvt3+6n2qKgovfvuu2rXrp2yZcumyMhI/d///Z9OnTqlpk2bKlu2bCpZsqQ2bNhgXyb5yO28efNUuHBheXl5qW7dujp06JDDtiZOnKgCBQrIw8NDRYoU0fTp0x3m22w2ffrpp2ratKl8fX318ssvq2bNmpKkHDlyyGazqUOHDpKkxYsXq1q1asqePbuCgoLUuHFj7dmzx76u5B7NnTtXNWvWlI+Pj0qXLq01a9Y4bPPXX39V9erV5ePjoxw5cig6Olrnzp2TJBljNHr0aOXPn1/e3t4qXbq0vvnmmzT7CeAByOD3igcAS7Rv3940bdo0xXmLFy82/v7+JjY21uzZs8f8+OOPJioqysTExNjHvP/++2b58uVm7969ZtmyZaZIkSLmtddeM8YYEx8fb8aPH2/8/f3NsWPHzLFjx0xcXJwxxhhJ5ttvv3XYXkBAgJk6daoxxph9+/YZSSYqKsrMmTPH7N271xw5csR8/vnnJleuXPZpc+bMMYGBgSY2NjbVfaxevbrp1q2b/XVkZKQJDAw0n376qdm5c6d57bXXjJ+fn6lfv7756quvzI4dO8xTTz1lihUrZpKSkowxxkydOtW4u7ub8uXLm9WrV5sNGzaYChUqmCpVqtjXO3fuXOPu7m4+/vhjs2PHDjN27Fjj6upqli9fbh8jyYSGhpopU6aYPXv2mP3795s5c+YYSWbHjh3m2LFj5vz588YYY7755hszZ84cs3PnTrNp0ybTpEkTU7JkSXPjxg2HHhUtWtQsXLjQ7Nixwzz77LMmMjLSJCQkGGOM2bRpk/H09DSvvfaa2bx5s9m6dauZMGGCOXXqlDHGmAEDBpiiRYuaxYsXmz179pipU6caT09Ps3LlylT7CeD+I3gCyBLat29vXF1dja+vr/3j2WefNcYY8/jjj5vhw4c7jJ8+fbrJlStXquv76quvTFBQkP311KlTTUBAgNO4uw2e48ePdxgTERFhvvjiC4dpQ4cONZUrV061ppSC5/PPP29/fezYMSPJDBo0yD5tzZo1RpI5duyYfT8kmbVr19rHbN++3Ugyv/32mzHGmCpVqpiOHTs6bLt58+amYcOGDvvdvXt3hzErVqwwksy5c+dS3QdjjDl58qSRZLZs2WKM+V+PJk+ebB/z119/GUlm+/btxhhjWrVqZapWrZri+i5dumS8vLzM6tWrHaa/9NJLplWrVmnWAuD+4hpPAFlGzZo1NXHiRPtrX19fSdLGjRu1fv16DRs2zD7vxo0bunbtmq5cuSIfHx+tWLFCw4cP17Zt23Tx4kUlJibq2rVrunz5sn09/0T58uXtn586dUqHDh3SSy+9pI4dO9qnJyYmKiAg4J7WW6pUKfvnOXPmlCSVLFnSadrJkycVFhYmSXJzc3Oop2jRosqePbu2b9+uChUqaPv27XrllVcctlO1alV98MEHqe5TWvbs2aNBgwZp7dq1On36tJKSkiRJBw8eVIkSJVLcl1y5ctnrLlq0qDZv3qzmzZunuP5t27bp2rVrqlu3rsP069evq2zZsndVI4D7g+AJIMvw9fVVwYIFnaYnJSVpyJAhatasmdM8Ly8vHThwQA0bNlSnTp00dOhQBQYG6pdfftFLL710x5tmbDabjDEO01Ja5tbwmhy8Jk2apIoVKzqMS74m9W7depOSzWZLdVryNm+fntq02+cbY5ym3W0gb9KkiSIiIjRp0iSFh4crKSlJJUqU0PXr1++4L8l1e3t7p7r+5DHfffedcufO7TDP09PzrmoEcH8QPAFkeY8++qh27NiRYiiVpA0bNigxMVFjx46Vi8vNezK/+uorhzEeHh66ceOG07IhISE6duyY/fWuXbt05cqVNOvJmTOncufOrb1796pNmzb3ujv/WGJiojZs2KAKFSpIknbs2KHz58+raNGikqRixYrpl19+Ubt27ezLrF69WsWKFUtzvR4eHpLk0KczZ85o+/bt+uyzz/T4449Lkn755Zd7rrlUqVJatmyZhgwZ4jSvePHi8vT01MGDB1W9evV7XjeA+4fgCSDLe/vtt9W4cWNFRESoefPmcnFx0Z9//qktW7bo3XffVYECBZSYmKgJEyaoSZMm+vXXX/Xpp586rCMqKkqXLl3SsmXLVLp0afn4+MjHx0e1atXSRx99pEqVKikpKUl9+/a9q0clxcTEqGvXrvL391eDBg0UHx+vDRs26Ny5c+rRo8eDaoWkm0cW33jjDX344Ydyd3dXly5dVKlSJXsQ7d27t1q0aKFHH31UtWvX1oIFCzR37lwtXbo0zfVGRkbKZrNp4cKFatiwoby9vZUjRw4FBQXp888/V65cuXTw4EH169fvnmvu37+/SpYsqc6dO6tTp07y8PDQihUr1Lx5cwUHB6tXr1568803lZSUpGrVqunixYtavXq1smXLpvbt26erTwDSIaMvMgUAK6R1V7sxN+9sr1KlivH29jb+/v6mQoUK5vPPP7fPHzdunMmVK5fx9vY20dHRZtq0aU43ynTq1MkEBQUZSWbw4MHGGGOOHDli6tWrZ3x9fU2hQoXMokWLUry5aNOmTU41zZw505QpU8Z4eHiYHDlymCeeeMLMnTs31X1I6eai999/32GMbrvZ6fbtJ98kNWfOHJM/f37j4eFhatWqZfbv3++wnk8++cTkz5/fuLu7m8KFC5tp06aluZ1k77zzjgkLCzM2m820b9/eGGPMkiVLTLFixYynp6cpVaqUWblypcPyKfXo3LlzRpJZsWKFfdrKlStNlSpVjKenp8mePbuJjo62f32SkpLMBx98YIoUKWLc3d1NSEiIiY6ONqtWrUq1nwDuP5sxt118BADIsmJjY9W9e3feXQjAA8ED5AEAAGAJgicAAAAswal2AAAAWIIjngAAALAEwRMAAACWIHgCAADAEgRPAAAAWILgCQAAAEsQPAEAAGAJgicAAAAsQfAEAACAJQieAAAAsMT/A1B+zOIoBP+JAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(models[.9], importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9753356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for batters with more than 60 plate appearances: 0.04004975941006881\n",
      "Grouped RMSE 0.11075920204228619\n"
     ]
    }
   ],
   "source": [
    "grouped_results = results_df.groupby(['year', 'batter'])[['actual', 'predicted']].agg(['mean', 'count'])\n",
    "grouped_results.columns = ['_'.join(col).strip() for col in grouped_results.columns.values]\n",
    "grouped_results = grouped_results.reset_index()\n",
    "grouped_rmse = np.sqrt(mean_squared_error(grouped_results['actual_mean'], grouped_results['predicted_mean']))\n",
    "qualified_results = grouped_results[grouped_results['actual_count'] > 60]\n",
    "qualified_rmse = np.sqrt(mean_squared_error(qualified_results['actual_mean'], qualified_results['predicted_mean']))\n",
    "print(f'RMSE for batters with more than 60 plate appearances: {qualified_rmse}')\n",
    "print(f'Grouped RMSE {grouped_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4f868",
   "metadata": {},
   "source": [
    "##### Find Quintiles for Each Data Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e4859dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n"
     ]
    }
   ],
   "source": [
    "quantile_predictions = pd.DataFrame()\n",
    "\n",
    "for q in models:\n",
    "    quantile_predictions[f'q_{q}'] = models[q].predict(x_25)\n",
    "\n",
    "quantile_predictions.set_index(x_25.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdeccc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_predictions['name'] = df_25['batter']\n",
    "quantile_predictions['year'] = df_25['year']\n",
    "quantile_cols = sorted([col for col in quantile_predictions.columns if col.startswith('q_')])\n",
    "quantile_predictions[quantile_cols] = np.sort(quantile_predictions[quantile_cols].values, axis=1)\n",
    "quantile_predictions[quantile_cols] = quantile_predictions[quantile_cols].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80a8063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 players with highest prediction standard deviation:\n",
      "name\n",
      "cal raleigh       0.062546\n",
      "mike trout        0.060314\n",
      "austin wynns      0.060170\n",
      "eugenio suarez    0.060006\n",
      "danny jansen      0.058045\n",
      "Name: pred_std, dtype: float64\n",
      "Top 5 players with lowest prediction standard deviation:\n",
      "name\n",
      "tyler wade           0.034972\n",
      "david hamilton       0.036034\n",
      "nick martini         0.036820\n",
      "christian vazquez    0.037415\n",
      "jake fraley          0.037525\n",
      "Name: pred_std, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "player_quant = quantile_predictions.groupby('name').mean()\n",
    "player_quant['pitch_count'] = quantile_predictions.groupby('name').size()\n",
    "player_quant['pred_std'] = player_quant[quantile_cols].std(axis=1)\n",
    "player_quant = player_quant[player_quant['pitch_count'] > 60]\n",
    "\n",
    "\n",
    "# Find and print the top 5 players with the highest standard deviation\n",
    "print(\"Top 5 players with highest prediction standard deviation:\")\n",
    "top_5_highest_std = player_quant.nlargest(5, 'pred_std')\n",
    "print(top_5_highest_std['pred_std'])\n",
    "\n",
    "# Find and print the top 5 players with the lowest standard deviation\n",
    "print(\"Top 5 players with lowest prediction standard deviation:\")\n",
    "top_5_lowest_std = player_quant.nsmallest(5, 'pred_std')\n",
    "print(top_5_lowest_std['pred_std'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
