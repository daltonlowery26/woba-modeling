{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66563c33",
   "metadata": {},
   "source": [
    "### lgb to model wobacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a80e416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, PredefinedSplit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b48f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Projects/Coding Projects/woba modeling/data/')\n",
    "df = pd.read_csv('pitch/pitch_cleaned.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16116f",
   "metadata": {},
   "source": [
    "##### Cleaning for Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abeb93ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df[df['description'] == 'hit_into_play']\n",
    "df = df[['batter','year', 'woba_value', 'launch_speed', 'launch_angle', 'spray_angle']]\n",
    "df = df[df['launch_speed'].notna()] # mcar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d897b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd80137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['year'] < 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "748ae828",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (df_train[['launch_speed', 'launch_angle', 'spray_angle']])\n",
    "y = df_train['woba_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37995345",
   "metadata": {},
   "source": [
    "##### Train Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2cc10",
   "metadata": {},
   "source": [
    "no need for a test set as I am purposely holding out 2025 data. I want to test on all 2025 data to compare the predection power of this model to xwobacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "588c9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=26) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bc7ff",
   "metadata": {},
   "source": [
    "##### Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c50c75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor(random_state=26, n_jobs=-1, metric='quantile', objective='quantile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e450d758",
   "metadata": {},
   "source": [
    "##### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7800b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d0904ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Randomized Search for quantile: 0.1\n",
      "<bound method LGBMModel.get_params of LGBMRegressor(alpha=0.1, max_bin=63, metric='quantile', n_jobs=-1,\n",
      "              objective='quantile', random_state=26)>\n",
      "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 200 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1398, in fit\n    super().fit(\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 949, in fit\n    _X, _y = _LGBMValidateData(\n             ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\lightgbm\\compat.py\", line 78, in validate_data\n    X, y = check_X_y(\n           ^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1318, in check_X_y\n    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1340, in _check_y\n    _assert_all_finite(y, input_name=\"y\", estimator_name=estimator_name)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input y contains NaN.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(alpha\u001b[38;5;241m=\u001b[39mq)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mget_params)\n\u001b[1;32m---> 38\u001b[0m search \u001b[38;5;241m=\u001b[39m \u001b[43mrnd_searcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for quantile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest score for quantile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1959\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:995\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    993\u001b[0m     )\n\u001b[1;32m--> 995\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 200 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1398, in fit\n    super().fit(\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 949, in fit\n    _X, _y = _LGBMValidateData(\n             ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\lightgbm\\compat.py\", line 78, in validate_data\n    X, y = check_X_y(\n           ^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1318, in check_X_y\n    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1340, in _check_y\n    _assert_all_finite(y, input_name=\"y\", estimator_name=estimator_name)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input y contains NaN.\n"
     ]
    }
   ],
   "source": [
    "rnd_search_params = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'learning_rate': [0.1, 0.01, 0.005],          \n",
    "    'num_leaves': np.linspace(2, 200, 25, dtype=int),\n",
    "    'max_depth': np.linspace(2, 15, 7, dtype=int),  \n",
    "    'min_data_in_leaf': np.linspace(1, 30, 10, dtype=int),         \n",
    "    'subsample': np.linspace(0.3, 0.8, 7),               \n",
    "    'colsample_bytree': np.linspace(0.6, 1.0, 5),\n",
    "    'n_estimators': np.linspace(100, 2000, 15, dtype=int),\n",
    "    'lambda_l2': [1, 3, 5, 10, 20, 25, 50],\n",
    "    'lambda_l1': [0.001, 0.01, 1, 3, 5]\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\": [lgb.early_stopping(stopping_rounds=40, verbose=False)], \n",
    "    \"eval_set\": [(x_val, y_val)],\n",
    "    \"eval_metric\": \"rmse\" \n",
    "}\n",
    "\n",
    "# for early stopping\n",
    "x_combined = np.concatenate((x_train, x_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "split_index = [-1] * len(x_train) + [0] * len(x_val)\n",
    "pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "all_best_params = {}\n",
    "all_best_scores = {}\n",
    "\n",
    "model.set_params(max_bin=63)\n",
    "for q in quantiles:\n",
    "    print(f\"Running Randomized Search for quantile: {q}\")\n",
    "    \n",
    "    rnd_searcher = RandomizedSearchCV(model, param_distributions=rnd_search_params, cv=pds,\n",
    "                                    n_iter=200, random_state=26, verbose=1, n_jobs=5) \n",
    "    \n",
    "    model.set_params(alpha=q)\n",
    "    print(model.get_params)\n",
    "    search = rnd_searcher.fit(x_combined, y_combined, **fit_params)\n",
    "    \n",
    "    print(f\"Best parameters for quantile {q}: {search.best_params_}\")\n",
    "    print(f\"Best score for quantile {q}: {search.best_score_}\")\n",
    "    \n",
    "    all_best_params[q] = search.best_params_\n",
    "    all_best_scores[q] = search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac5100",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00bc454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'boosting_type': ['dart', 'gbdt'],\n",
    "        'subsample': [0.45, 0.5, 0.55], \n",
    "        'num_leaves':  [8, 9, 10], \n",
    "        'n_estimators': [350, 400, 450], \n",
    "        'min_data_in_leaf': [16, 18, 20], \n",
    "        'max_depth': [8, 9], \n",
    "        'max_bin': [63], \n",
    "        'learning_rate': [0.1, 0.15], \n",
    "        'lambda_l2': [0.5, 1], \n",
    "        'colsample_bytree': [0.75, 0.8]\n",
    "        }\n",
    "\n",
    "\n",
    "# for early stopping\n",
    "x_combined = np.concatenate((x_train, x_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "split_index = [-1] * len(x_train) + [0] * len(x_val)\n",
    "pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\": [lgb.early_stopping(stopping_rounds=40, verbose=False)], \n",
    "    \"eval_set\": [(x_val, y_val)],\n",
    "    \"eval_metric\": \"rmse\" \n",
    "}\n",
    "\n",
    "\n",
    "grid_searcher = GridSearchCV(model, param_grid=grid, cv=pds, verbose=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aaf053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 2592 candidates, totalling 2592 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 266\n",
      "[LightGBM] [Info] Number of data points in the train set: 169715, number of used features: 5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Start training from score 0.373572\n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'lambda_l2': 1, 'learning_rate': 0.15, 'max_bin': 63, 'max_depth': 8, 'min_data_in_leaf': 18, 'n_estimators': 350, 'num_leaves': 9, 'subsample': 0.45}\n",
      "0.22591349039763697\n",
      "['Column_0' 'Column_1' 'Column_2' 'Column_3' 'Column_4']\n"
     ]
    }
   ],
   "source": [
    "grid_searcher.fit(x_combined, y_combined, **fit_params)\n",
    "print(grid_searcher.best_params_)\n",
    "print(grid_searcher.best_score_)\n",
    "print(grid_searcher.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4afe9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best = {'objective':'regression', 'type': 'quantilie', 'boosting_type': 'dart', 'colsample_bytree': 0.75, 'lambda_l2': 1, 'learning_rate': 0.15, 'max_bin': 63, 'max_depth': 8, 'min_data_in_leaf': 18, 'n_estimators': 350, 'num_leaves': 9, 'subsample': 0.45}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa024a79",
   "metadata": {},
   "source": [
    "#### Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c215ee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best param\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_numpy_types(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_numpy_types(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [convert_numpy_types(i) for i in obj]\n",
    "    return obj\n",
    "\n",
    "serializable_params = convert_numpy_types(all_best_params)\n",
    "\n",
    "with open('ev_dir_params.json', 'w') as f:\n",
    "    json.dump(serializable_params, f, indent=4)\n",
    "\n",
    "print(\"Saved best param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f8995a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 623491, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Start training from score 0.385357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 623491, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Start training from score 0.385357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 623491, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Start training from score 0.385357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 623491, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Start training from score 0.385357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 623491, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Start training from score 0.385357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 623491, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Start training from score 0.385357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 623491, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Info] Start training from score 0.385357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 623491, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Start training from score 0.385357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 623491, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Info] Start training from score 0.385357\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for q in quantiles:\n",
    "    quantile_model = lgb.LGBMRegressor(**all_best_params[q], alpha=q, random_state=26, n_jobs=-1)\n",
    "    quantile_model.fit(x_train, y_train, \n",
    "                       eval_set=[(x_val, y_val)], \n",
    "                       callbacks=[lgb.early_stopping(stopping_rounds=40, verbose=False)])\n",
    "    models[q] = quantile_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f1543",
   "metadata": {},
   "source": [
    "##### Testing on 2025 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d221207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_25 = df[df['year'] == 2025]\n",
    "x_25 = df_25[['launch_speed', 'launch_angle', 'spray_angle']]\n",
    "y_25 = df_25['woba_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f355e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "RMSE: 0.39599520591156784\n"
     ]
    }
   ],
   "source": [
    "y_pred = models[.5].predict(x_25)\n",
    "rmse = np.sqrt(mean_squared_error(y_25, y_pred))\n",
    "results_df = pd.DataFrame({'actual': y_25, 'predicted': y_pred})\n",
    "results_df = results_df.join(df[['batter', 'year']])\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e96e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(models[.9], importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9753356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for batters with more than 60 plate appearances: 0.050049047862626456\n",
      "Grouped RMSE 0.11741470629300413\n"
     ]
    }
   ],
   "source": [
    "grouped_results = results_df.groupby(['year', 'batter'])[['actual', 'predicted']].agg(['mean', 'count'])\n",
    "grouped_results.columns = ['_'.join(col).strip() for col in grouped_results.columns.values]\n",
    "grouped_results = grouped_results.reset_index()\n",
    "grouped_rmse = np.sqrt(mean_squared_error(grouped_results['actual_mean'], grouped_results['predicted_mean']))\n",
    "qualified_results = grouped_results[grouped_results['actual_count'] > 60]\n",
    "qualified_rmse = np.sqrt(mean_squared_error(qualified_results['actual_mean'], qualified_results['predicted_mean']))\n",
    "print(f'RMSE for batters with more than 60 plate appearances: {qualified_rmse}')\n",
    "print(f'Grouped RMSE {grouped_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4f868",
   "metadata": {},
   "source": [
    "##### Find Quintiles for Each Data Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e4859dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n"
     ]
    }
   ],
   "source": [
    "quantile_predictions = pd.DataFrame()\n",
    "\n",
    "for q in models:\n",
    "    quantile_predictions[f'q_{q}'] = models[q].predict(x_25)\n",
    "\n",
    "quantile_predictions.set_index(x_25.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdeccc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_predictions['name'] = df_25['batter']\n",
    "quantile_predictions['year'] = df_25['year']\n",
    "quantile_cols = sorted([col for col in quantile_predictions.columns if col.startswith('q_')])\n",
    "quantile_predictions[quantile_cols] = np.sort(quantile_predictions[quantile_cols].values, axis=1)\n",
    "quantile_predictions[quantile_cols] = quantile_predictions[quantile_cols].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80a8063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 players with highest prediction standard deviation:\n",
      "name\n",
      "cal raleigh      0.056527\n",
      "shohei ohtani    0.055105\n",
      "jake bauers      0.054893\n",
      "kyle stowers     0.054624\n",
      "danny jansen     0.053157\n",
      "Name: pred_std, dtype: float64\n",
      "Top 5 players with lowest prediction standard deviation:\n",
      "name\n",
      "david hamilton    0.028481\n",
      "jonah bride       0.029157\n",
      "tyler wade        0.029604\n",
      "nick martini      0.029778\n",
      "lane thomas       0.031250\n",
      "Name: pred_std, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "player_quant = quantile_predictions.groupby('name').mean()\n",
    "player_quant['pitch_count'] = quantile_predictions.groupby('name').size()\n",
    "player_quant['pred_std'] = player_quant[quantile_cols].std(axis=1)\n",
    "player_quant = player_quant[player_quant['pitch_count'] > 60]\n",
    "\n",
    "\n",
    "# Find and print the top 5 players with the highest standard deviation\n",
    "print(\"Top 5 players with highest prediction standard deviation:\")\n",
    "top_5_highest_std = player_quant.nlargest(5, 'pred_std')\n",
    "print(top_5_highest_std['pred_std'])\n",
    "\n",
    "# Find and print the top 5 players with the lowest standard deviation\n",
    "print(\"Top 5 players with lowest prediction standard deviation:\")\n",
    "top_5_lowest_std = player_quant.nsmallest(5, 'pred_std')\n",
    "print(top_5_lowest_std['pred_std'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
