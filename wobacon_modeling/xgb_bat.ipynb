{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66563c33",
   "metadata": {},
   "source": [
    "### Using xgb to model wobacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80e416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, PredefinedSplit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b48f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Projects/Coding Projects/woba modeling/data/')\n",
    "df = pd.read_csv('pitch_cleaned.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16116f",
   "metadata": {},
   "source": [
    "##### Cleaning for Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abeb93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['description'] == 'hit_into_play']\n",
    "df = df[df['attack_direction'].notna()] # mar, but higher substinally higher avg woba on missing. going to adress with a launch angle, launch speed model\n",
    "df = df[df['launch_speed'].notna()] # mcar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d897b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zone'] = df['zone'].astype('category')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748ae828",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (df[['zone', 'launch_speed', 'swing_path_tilt', 'attack_angle', 'attack_direction']])\n",
    "y = df['woba_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37995345",
   "metadata": {},
   "source": [
    "##### Train Test Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588c9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=26)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.125, random_state=26) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bc7ff",
   "metadata": {},
   "source": [
    "##### Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(random_state=26, n_jobs=-1, metric=['mae', 'rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d0904ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_params = {\n",
    "    'learning_rate': np.linspace(0.005, 0.2, 10),          \n",
    "    'num_leaves': np.linspace(2, 100, 10, dtype=int),\n",
    "    'max_depth': np.linspace(1, 15, 20, dtype=int),  \n",
    "    'min_data_in_leaf': np.linspace(1, 30, 10, dtype=int),         \n",
    "    'subsample': np.linspace(0.4, 0.9, 7),               \n",
    "    'max_bin': np.linspace(200, 600, 10, dtype=int),\n",
    "    'colsample_bytree': np.linspace(0.6, 1.0, 5),\n",
    "    'n_estimators': np.linspace(200, 2000, 15, dtype=int),\n",
    "    'lambda_l2': np.linspace(0.01, 0.5, 15)\n",
    "}\n",
    "\n",
    "x_combined = pd.concat([x_train, x_val])\n",
    "y_combined = pd.concat([y_train, y_val])\n",
    "\n",
    "test_fold = np.zeros(len(x_combined))\n",
    "test_fold[:len(x_train)] = -1\n",
    "pds = PredefinedSplit(test_fold)\n",
    "\n",
    "fit_params = {'eval_set': [(x_val, y_val)], 'verbose': False}\n",
    "\n",
    "rnd_searcher = RandomizedSearchCV(model, param_distributions=rnd_search_params, cv=pds,\n",
    "                                n_iter=500, random_state=26, verbose=4, n_jobs=-1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6858e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 500 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 500 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n500 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1081, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 596, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1008, in _create_dmatrix\n    return DMatrix(**kwargs, nthread=self.n_jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 878, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n                                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1223, in dispatch_data_backend\n    return _from_pandas_df(\n           ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 640, in _from_pandas_df\n    df, feature_names, feature_types = _transform_pandas_df(\n                                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 603, in _transform_pandas_df\n    pandas_check_dtypes(data, enable_categorical)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 569, in pandas_check_dtypes\n    _invalid_dataframe_dtype(data)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 356, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:zone: category\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m search \u001b[38;5;241m=\u001b[39m \u001b[43mrnd_searcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1959\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:995\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    993\u001b[0m     )\n\u001b[1;32m--> 995\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 500 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n500 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1081, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 596, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1008, in _create_dmatrix\n    return DMatrix(**kwargs, nthread=self.n_jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 878, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n                                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1223, in dispatch_data_backend\n    return _from_pandas_df(\n           ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 640, in _from_pandas_df\n    df, feature_names, feature_types = _transform_pandas_df(\n                                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 603, in _transform_pandas_df\n    pandas_check_dtypes(data, enable_categorical)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 569, in pandas_check_dtypes\n    _invalid_dataframe_dtype(data)\n  File \"c:\\Users\\dalto\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 356, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:zone: category\n"
     ]
    }
   ],
   "source": [
    "search = rnd_searcher.fit(x_combined, y_combined, **fit_params)\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "print(search.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "00bc454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'boosting_type': ['dart', 'gdbt'],\n",
    "        'subsample': [0.45, 0.5, 0.55], \n",
    "        'num_leaves':  [8, 9, 10], \n",
    "        'n_estimators': [350, 400, 450], \n",
    "        'min_data_in_leaf': [16, 18, 20], \n",
    "        'max_depth': [8, 9, 10], \n",
    "        'max_bin': [63], \n",
    "        'learning_rate': [0.05 ,0.1, 0.15], \n",
    "        'lambda_l2': [0.5, 1, 3], \n",
    "        'colsample_bytree': [0.75,0.8, 0.85]\n",
    "        }\n",
    "\n",
    "grid_searcher = GridSearchCV(model, param_grid=grid, cv=pds, verbose=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 13122 candidates, totalling 13122 fits\n"
     ]
    }
   ],
   "source": [
    "grid_searcher.fit(x_combined, y_combined, **fit_params)\n",
    "print(grid_searcher.best_params_)\n",
    "print(grid_searcher.best_score_)\n",
    "print(grid_searcher.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a4afe9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best = {'boosting_type': 'dart','colsample_bytree': 0.8, 'lambda_l2': 0.5, 'learning_rate': 0.1, 'max_bin': 63, 'max_depth': 9, 'min_data_in_leaf': 18, 'n_estimators': 400, 'num_leaves': 9, 'subsample': 0.5, 'early_stopping_rounds': 40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8f8995a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5\n",
      "[LightGBM] [Warning] early_stopping_round is set=40, early_stopping_rounds=40 will be ignored. Current value: early_stopping_round=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 266\n",
      "[LightGBM] [Info] Number of data points in the train set: 160406, number of used features: 5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5\n",
      "[LightGBM] [Warning] early_stopping_round is set=40, early_stopping_rounds=40 will be ignored. Current value: early_stopping_round=40\n",
      "[LightGBM] [Info] Start training from score 0.372028\n",
      "Training until validation scores don't improve for 40 rounds\n"
     ]
    }
   ],
   "source": [
    "model = model.set_params(**grid_best)\n",
    "model = model.fit(x_train, y_train, eval_set=[[x_val, y_val]], callbacks=[lgb.early_stopping(stopping_rounds=40, verbose=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f355e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5\n",
      "RMSE: 0.5033683310184024\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "results_df = pd.DataFrame({'actual': y_test, 'predicted': y_pred})\n",
    "results_df = results_df.join(df[['batter', 'year']])\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d0e96e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[258 428 211 341 354]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9753356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for batters with more than 60 plate appearances: 0.07396243072837254\n",
      "Grouped RMSE 0.17253456466657058\n"
     ]
    }
   ],
   "source": [
    "grouped_results = results_df.groupby(['year', 'batter'])[['actual', 'predicted']].agg(['mean', 'count'])\n",
    "grouped_results.columns = ['_'.join(col).strip() for col in grouped_results.columns.values]\n",
    "grouped_results = grouped_results.reset_index()\n",
    "grouped_rmse = np.sqrt(mean_squared_error(grouped_results['actual_mean'], grouped_results['predicted_mean']))\n",
    "qualified_results = grouped_results[grouped_results['actual_count'] > 40]\n",
    "qualified_rmse = np.sqrt(mean_squared_error(qualified_results['actual_mean'], qualified_results['predicted_mean']))\n",
    "print(f'RMSE for batters with more than 60 plate appearances: {qualified_rmse}')\n",
    "print(f'Grouped RMSE {grouped_rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
