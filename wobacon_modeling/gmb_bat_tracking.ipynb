{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66563c33",
   "metadata": {},
   "source": [
    "### Using lightgmb to model wobacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80e416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, PredefinedSplit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b48f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Projects/Coding Projects/woba modeling/data/')\n",
    "df = pd.read_csv('pitch_cleaned.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16116f",
   "metadata": {},
   "source": [
    "##### Cleaning for Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2f0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['year'] < 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abeb93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['description'] == 'hit_into_play']\n",
    "df = df[df['attack_direction'].notna()] # mar, but higher substinally higher avg woba on missing. going to adress with a launch angle, launch speed model\n",
    "df = df[df['launch_speed'].notna()] # mcar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d897b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zone'] = df['zone'].astype('category')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "748ae828",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (df[['zone', 'launch_speed', 'swing_path_tilt', 'attack_angle', 'attack_direction']])\n",
    "y = df['woba_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37995345",
   "metadata": {},
   "source": [
    "##### Train Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2cc10",
   "metadata": {},
   "source": [
    "no need for a test set as I am purposely holding out 2025 data. I want to test on all 2025 data to compare the predection power of this model to xwobacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "588c9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=26) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bc7ff",
   "metadata": {},
   "source": [
    "##### Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50c75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor(random_state=26, n_jobs=-1, metric=['mae', 'rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e450d758",
   "metadata": {},
   "source": [
    "##### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0904ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_params = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'learning_rate': np.linspace(0.005, 0.2, 10),          \n",
    "    'num_leaves': np.linspace(2, 100, 10, dtype=int),\n",
    "    'max_depth': np.linspace(1, 15, 20, dtype=int),  \n",
    "    'min_data_in_leaf': np.linspace(1, 30, 10, dtype=int),         \n",
    "    'subsample': np.linspace(0.4, 0.9, 7),               \n",
    "    'max_bin': np.linspace(200, 600, 10, dtype=int),\n",
    "    'colsample_bytree': np.linspace(0.6, 1.0, 5),\n",
    "    'n_estimators': np.linspace(200, 2000, 15, dtype=int),\n",
    "    'lambda_l2': np.linspace(0.01, 0.5, 15)\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\": [lgb.early_stopping(stopping_rounds=40, verbose=False)], \n",
    "    \"eval_set\": [(x_val, y_val)],\n",
    "    \"eval_metric\": \"rmse\" \n",
    "}\n",
    "\n",
    "# for early stopping\n",
    "x_combined = np.concatenate((x_train, x_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "split_index = [-1] * len(x_train) + [0] * len(x_val)\n",
    "pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "rnd_searcher = RandomizedSearchCV(model, param_distributions=rnd_search_params, cv=pds,\n",
    "                                n_iter=500, random_state=26, verbose=4, n_jobs=-1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f6858e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 500 candidates, totalling 500 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.02357142857142857, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02357142857142857\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.02357142857142857, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02357142857142857\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 816\n",
      "[LightGBM] [Info] Number of data points in the train set: 183322, number of used features: 6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.02357142857142857, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02357142857142857\n",
      "[LightGBM] [Info] Start training from score 0.372486\n",
      "{'subsample': 0.65, 'num_leaves': 12, 'n_estimators': 714, 'min_data_in_leaf': 20, 'max_depth': 5, 'max_bin': 200, 'learning_rate': 0.07, 'lambda_l2': 0.02357142857142857, 'colsample_bytree': 0.9, 'boosting_type': 'gbdt'}\n",
      "0.23143351520215694\n",
      "['Column_0' 'Column_1' 'Column_2' 'Column_3' 'Column_4' 'Column_5']\n"
     ]
    }
   ],
   "source": [
    "search = rnd_searcher.fit(x_combined, y_combined, **fit_params)\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "print(search.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac5100",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00bc454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'boosting_type': ['dart', 'gbdt'],\n",
    "        'subsample': [0.45, 0.5, 0.55], \n",
    "        'num_leaves':  [8, 9, 10], \n",
    "        'n_estimators': [350, 400, 450], \n",
    "        'min_data_in_leaf': [16, 18, 20], \n",
    "        'max_depth': [8, 9, 10], \n",
    "        'max_bin': [63], \n",
    "        'learning_rate': [0.05 ,0.1, 0.15], \n",
    "        'lambda_l2': [0.5, 1, 3], \n",
    "        'colsample_bytree': [0.75,0.8, 0.85]\n",
    "        }\n",
    "\n",
    "# for early stopping\n",
    "x_combined = np.concatenate((x_train, x_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)\n",
    "split_index = [-1] * len(x_train) + [0] * len(x_val)\n",
    "pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "fit_params = {\n",
    "    \"callbacks\": [lgb.early_stopping(stopping_rounds=40, verbose=False)], \n",
    "    \"eval_set\": [(x_val, y_val)],\n",
    "    \"eval_metric\": \"rmse\" \n",
    "}\n",
    "\n",
    "\n",
    "grid_searcher = GridSearchCV(model, param_grid=grid, cv=pds, verbose=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 13122 candidates, totalling 13122 fits\n"
     ]
    }
   ],
   "source": [
    "grid_searcher.fit(x_combined, y_combined, **fit_params)\n",
    "print(grid_searcher.best_params_)\n",
    "print(grid_searcher.best_score_)\n",
    "print(grid_searcher.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a4afe9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best = {'boosting_type': 'dart','colsample_bytree': 0.8, 'lambda_l2': 0.5, 'learning_rate': 0.1, 'max_bin': 63, 'max_depth': 9, 'min_data_in_leaf': 18, 'n_estimators': 400, 'num_leaves': 9, 'subsample': 0.5, 'early_stopping_rounds': 40}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa024a79",
   "metadata": {},
   "source": [
    "#### Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8f8995a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5\n",
      "[LightGBM] [Warning] early_stopping_round is set=40, early_stopping_rounds=40 will be ignored. Current value: early_stopping_round=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 266\n",
      "[LightGBM] [Info] Number of data points in the train set: 160406, number of used features: 5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5\n",
      "[LightGBM] [Warning] early_stopping_round is set=40, early_stopping_rounds=40 will be ignored. Current value: early_stopping_round=40\n",
      "[LightGBM] [Info] Start training from score 0.372028\n",
      "Training until validation scores don't improve for 40 rounds\n"
     ]
    }
   ],
   "source": [
    "model = model.set_params(**grid_best)\n",
    "model = model.fit(x_train, y_train, eval_set=[[x_val, y_val]], callbacks=[lgb.early_stopping(stopping_rounds=40, verbose=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f1543",
   "metadata": {},
   "source": [
    "##### Testing on 2025 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d221207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_25 = df[df['year'] == 2025]\n",
    "x_25 = df_25[['zone', 'launch_speed', 'swing_path_tilt', 'attack_angle', 'attack_direction']]\n",
    "y_25 = df_25['woba_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5\n",
      "RMSE: 0.5033683310184024\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_25)\n",
    "rmse = np.sqrt(mean_squared_error(y_25, y_pred))\n",
    "results_df = pd.DataFrame({'actual': y_25, 'predicted': y_pred})\n",
    "results_df = results_df.join(df[['batter', 'year']])\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d0e96e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[258 428 211 341 354]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9753356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for batters with more than 60 plate appearances: 0.07396243072837254\n",
      "Grouped RMSE 0.17253456466657058\n"
     ]
    }
   ],
   "source": [
    "grouped_results = results_df.groupby(['year', 'batter'])[['actual', 'predicted']].agg(['mean', 'count'])\n",
    "grouped_results.columns = ['_'.join(col).strip() for col in grouped_results.columns.values]\n",
    "grouped_results = grouped_results.reset_index()\n",
    "grouped_rmse = np.sqrt(mean_squared_error(grouped_results['actual_mean'], grouped_results['predicted_mean']))\n",
    "qualified_results = grouped_results[grouped_results['actual_count'] > 40]\n",
    "qualified_rmse = np.sqrt(mean_squared_error(qualified_results['actual_mean'], qualified_results['predicted_mean']))\n",
    "print(f'RMSE for batters with more than 60 plate appearances: {qualified_rmse}')\n",
    "print(f'Grouped RMSE {grouped_rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
